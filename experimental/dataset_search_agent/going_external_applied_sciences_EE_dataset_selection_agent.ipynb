{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8ZOvPltTsa3"
      },
      "source": [
        "**Earth Engine Dataset Retrieval and Visualizer Agent**\n",
        "\n",
        "Author: Renee Johnston (reneejohnston@google.com), Eliot Cowan (eliotc@google.com)\n",
        "\n",
        "Inspired by: Simon Ilyushchenko's (simonf@google.com) [EE Genie](https://github.com/google/earthengine-community/blob/master/experimental/ee_genie.ipynb)\n",
        "\n",
        "**Annoyance**\n",
        "\n",
        "Due to problems with Javascript/Python interaction, the agent has to stop running after it moves or pans geemap. When this happens, the agent icon will change to üôè. Just hit enter in the chat box when you see this to continue analysis.\n",
        "\n",
        "**Installation**\n",
        "\n",
        "To use it, you need two things:\n",
        "1. Earth Engine access\n",
        "2. Generative AI API key\n",
        "\n",
        "You need a Google Cloud Project to associate your requests with. [Use these instructions](https://developers.google.com/earth-engine/cloud/earthengine_cloud_project_setup) and set project_id to your Google Cloud Project ID in the cell below when prompted.\n",
        "\n",
        "Next you need to get a Generative AI API key [here](https://aistudio.google.com/app/prompts/new_chat). Be aware that you might need to pay\n",
        "for use of the Generative AI API.\n",
        "\n",
        "To save this key in the notebook, click on the key icon in Colab on the left-hand side and add your key as a secret with the name GOOGLE_API_KEY. Make sure the value has no newlines.\n",
        "\n",
        "Finally, run the first cell. You only need to do it once. Earth Engine client will ask you authenticate.\n",
        "\n",
        "To use the dataset search agent, run every cell, then scroll to the app at the bottom. If the app is stuck waiting for an LLM, you can reset the app: click on the `Runtime / Interrupt Execution menu item`, then hit run all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b09aYpe5k4W0"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "JZCitI4hRfrt"
      },
      "outputs": [],
      "source": [
        "#@title Install Python Libraries\n",
        "\n",
        "%%capture\n",
        "!pip install google_cloud_aiplatform langchain-community langchain_google_genai chromadb langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "riMVsnLuXaTq"
      },
      "outputs": [],
      "source": [
        "import contextlib\n",
        "import dateutil\n",
        "import io\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "import shutil\n",
        "import sys\n",
        "import threading\n",
        "import traceback\n",
        "import time\n",
        "\n",
        "import ee\n",
        "import geemap\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import vertexai\n",
        "from vertexai.preview.language_models import TextEmbeddingModel\n",
        "\n",
        "import google.ai.generativelanguage as glm\n",
        "import google.api_core\n",
        "from google.cloud import storage\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0eimc8scEH8"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tsxMngtXlxn"
      },
      "outputs": [],
      "source": [
        "# @title Please update the following fields with your cloud project.\n",
        "project_name = \"your_gcp_project\" #@param {type:\"string\"}\n",
        "vertex_ai_zone = \"us-central1\" #@param {type:\"string\"}\n",
        "#@markdown If you created a new .jsonl file of the Earth Engine catalog using the accompanying notebook, set the local or gcs path to that file here.\n",
        "ee_catalog_jsonl_path = \"gs://science-ai-ee-catalog-index/catalog_summaries.jsonl\" #@param {type:\"string\"}\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project=project_name)\n",
        "storage_client = storage.Client(project=project_name)\n",
        "bucket = storage_client.get_bucket('earthengine-stac')\n",
        "vertexai.init(project=project_name, location=vertex_ai_zone)\n",
        "\n",
        "# download pkl path\n",
        "if ee_catalog_jsonl_path.startswith('gs://'):\n",
        "  ee_client_bucket = google.cloud.storage.bucket.Bucket(storage_client, name=ee_catalog_jsonl_path.split('/')[2],user_project=project_name)\n",
        "  blob = ee_client_bucket.blob('/'.join(ee_catalog_jsonl_path.split('/')[3:]))\n",
        "  blob.download_to_filename('catalog_summaries.jsonl')\n",
        "else:\n",
        "  shutil.copyfile(ee_catalog_jsonl_path, 'catalog_summaries.jsonl')\n",
        "# Score to aim for (on the 0-1 scale). The exact meaning of what \"score\" means\n",
        "# is left to the LLM.\n",
        "target_score = 0.8\n",
        "\n",
        "# Count of analysis rounds\n",
        "iteration = 1\n",
        "\n",
        "Map = geemap.Map()\n",
        "Map.add(\"layer_manager\")\n",
        "\n",
        "analysis_model = None\n",
        "map_dirty = False\n",
        "\n",
        "image_model = genai.GenerativeModel('gemini-1.5-pro-exp-0801')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESeVud7llELN"
      },
      "source": [
        "# UI widget definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_741mumXw1T"
      },
      "outputs": [],
      "source": [
        "command_input = widgets.Text(\n",
        "    value = 'what datasets have information about active fires in California during the 2020 fire season?',\n",
        "    description='‚ùì',\n",
        "    layout=widgets.Layout(width='100%', height='50px')\n",
        ")\n",
        "\n",
        "command_output = widgets.Label(\n",
        "    value='Last command will be here',\n",
        ")\n",
        "\n",
        "status_label = widgets.Textarea(\n",
        "    value='LLM response will be here',\n",
        "    layout=widgets.Layout(width='50%', height='100px')\n",
        ")\n",
        "\n",
        "widget_height = \"400px\"\n",
        "debug_output = widgets.Output(layout={\n",
        "    'border': '1px solid black',\n",
        "    'height': widget_height,\n",
        "    'overflow': 'scroll',\n",
        "    'width': '500px',\n",
        "    'padding': '5px'\n",
        "})\n",
        "with debug_output:\n",
        "  print('DEBUG COLUMN\\n')\n",
        "\n",
        "chat_output = widgets.Output(layout={\n",
        "    'border': '1px solid black',\n",
        "    'height': '600px',\n",
        "    'overflow': 'scroll',\n",
        "    'width': '300px'})\n",
        "\n",
        "with chat_output:\n",
        "  print('CHAT COLUMN\\n')\n",
        "\n",
        "\n",
        "dataset_widget = widgets.Output(layout={'overflow': 'scroll',\n",
        "                                        'width': '600px'})\n",
        "\n",
        "# Function to update the DataFrame display\n",
        "def update_dataset_widget(df):\n",
        "    with dataset_widget:\n",
        "        # Clear previous output\n",
        "        dataset_widget.clear_output()\n",
        "        # Display the DataFrame\n",
        "        html = df.to_html(escape=False, index=False, table_id='dataframe-table')  # add an ID for styling\n",
        "        styled_html = f\"\"\"\n",
        "\u003cstyle\u003e\n",
        "    #dataframe-table {{\n",
        "        width: 100%;\n",
        "        table-layout: auto;\n",
        "        max-width: 100%;\n",
        "        overflow-x: auto;\n",
        "    }}\n",
        "    #dataframe-table th:nth-child(2), #dataframe-table td:nth-child(2) {{\n",
        "        max-width: 50px; /* Adjust as needed */\n",
        "        white-space: normal; /* Allows text wrapping */\n",
        "        word-wrap: break-word; /* Breaks long words */\n",
        "    }}\n",
        "    #dataframe-table a {{ /* Adds styling for hrefs */\n",
        "            color: blue;\n",
        "            text-decoration: underline;\n",
        "        }}\n",
        "\u003c/style\u003e\n",
        "{html}\n",
        "\"\"\"\n",
        "        display(HTML(styled_html))\n",
        "\n",
        "update_dataset_widget(pd.DataFrame([['Welcome','to','Science'],['AI\\'s','Earth','Engine'],['dataset','search','agent']],columns=['Title', 'id', 'description']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkNZLPA5LEra"
      },
      "outputs": [],
      "source": [
        "# Code Viewer Widget\n",
        "import pygments\n",
        "from pygments.lexers import PythonLexer\n",
        "from pygments.formatters import HtmlFormatter\n",
        "\n",
        "# Refresh interval in seconds for more responsiveness\n",
        "refresh_interval = 3\n",
        "\n",
        "# We define the widgets early because some functions will write to the debug\n",
        "# and/or chat panels.\n",
        "code_editor_file = \"code_editor_file.py\"\n",
        "os.system(f'rm {code_editor_file}; echo \"# Welcome to the Science AI Dataset Search Agent Code Editor.\\n# You can view the code being executed by the agent here\" \u003e\u003e {code_editor_file}')\n",
        "\n",
        "# Function to read the file content\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Function to write the file content\n",
        "def write_file(file_path, content):\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "# Function to highlight and display code\n",
        "def highlight_code(code):\n",
        "    formatter = HtmlFormatter(style='default', full=True, linenos=True)\n",
        "    return pygments.highlight(code, PythonLexer(), formatter)\n",
        "\n",
        "# Define a global flag for stopping the thread\n",
        "stop_event = threading.Event()\n",
        "\n",
        "# Function to periodically refresh the code editor\n",
        "def refresh_code_editor():\n",
        "    while not stop_event.is_set():\n",
        "        time.sleep(refresh_interval)  # Wait for a specified interval\n",
        "        code = read_file(code_editor_file)\n",
        "        code_editor.value = highlight_code(code)  # Update editor with highlighted code\n",
        "\n",
        "# Create a widget to display highlighted code\n",
        "code_editor = widgets.HTML(\n",
        "    value=highlight_code(read_file(code_editor_file)),\n",
        "    layout=widgets.Layout(width='300px', height='300px')\n",
        ")\n",
        "\n",
        "# Ensure that the previous thread is cleaned up\n",
        "def cleanup_thread():\n",
        "    if 'code_editor_refresh_thread' in globals():\n",
        "        stop_event.set()\n",
        "        code_editor_refresh_thread.join()\n",
        "        del globals()['code_editor_refresh_thread']\n",
        "        stop_event.clear()\n",
        "\n",
        "# Cleanup any existing thread before starting a new one. This is a colab\n",
        "# notebook so without a cleanup, running the cell twice would cause multiple\n",
        "# competeting threads.\n",
        "cleanup_thread()\n",
        "\n",
        "# Start a new background thread to refresh the code editor\n",
        "code_editor_refresh_thread = threading.Thread(target=refresh_code_editor, daemon=True)\n",
        "code_editor_refresh_thread.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUxyUVnAlNeI"
      },
      "source": [
        "# Simple functions that LLM will call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFGHx043YOsg"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import runpy\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def set_center(x: float, y: float, zoom: int) -\u003e str:\n",
        "    \"\"\"Sets the map center to the given coordinates and zoom level and\n",
        "    returns instructions on what to do next.\"\"\"\n",
        "    with debug_output:\n",
        "     print(f\"SET_CENTER({x}, {y}, {zoom})\\n\")\n",
        "    Map.set_center(x, y)\n",
        "    Map.zoom = zoom\n",
        "    global map_dirty\n",
        "    map_dirty = True\n",
        "    return (\n",
        "      'Do not call any more functions in this request to let geemap bounds '\n",
        "      'update. Wait for user input.')\n",
        "\n",
        "def add_image_layer(image_id: str) -\u003e str:\n",
        "    \"\"\"Adds to the map center an ee.Image with the given id\n",
        "    and returns status message (success or failure).\"\"\"\n",
        "    Map.clear()\n",
        "    command_output.value = f\"add_image_layer('{image_id}')\"\n",
        "    Map.addLayer(ee.Image(image_id))\n",
        "    return 'success'\n",
        "\n",
        "def _get_dataset_code_sample(catalog_url: str):\n",
        "  \"\"\"Fetches the Javascript and/or Python code sample on a EE catalog page.\"\"\"\n",
        "  response = requests.get(catalog_url)\n",
        "  code_sample = \"\"\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "      html_content = response.content\n",
        "      soup = BeautifulSoup(html_content, 'lxml')\n",
        "\n",
        "      # Extract JavaScript and Python Earth Engine code\n",
        "      codes = {}\n",
        "      for pre in soup.find_all('pre'):\n",
        "          # Get the language of the code\n",
        "          lang = pre.get('class', [])\n",
        "          if 'lang-javascript' in lang:\n",
        "              codes['JavaScript'] = pre.get_text(strip=True)\n",
        "          elif 'lang-python' in lang:\n",
        "              codes['Python'] = pre.get_text(strip=True)\n",
        "\n",
        "      # Print the extracted code\n",
        "      if not codes:\n",
        "          return \"No code snippets found.\"\n",
        "      else:\n",
        "          for lang, code in codes.items():\n",
        "              code_sample += \"--- \" + lang + \" Code ---\\n\"\n",
        "              code_sample += code + \"\\n\"\n",
        "          return code_sample\n",
        "  else:\n",
        "      raise RuntimeError(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
        "\n",
        "def get_dataset_description(dataset_id: str) -\u003e str:\n",
        "  \"\"\"Fetches JSON STAC description for the given Earth Engine dataset id.\n",
        "  This function can be used to access all available metadata about an Earth\n",
        "  Engine dataset, including examples of visualization parameters.\"\"\"\n",
        "  with debug_output:\n",
        "    print(f'LOOKING UP {dataset_id}\\n')\n",
        "  parent = dataset_id.split('/')[0]\n",
        "\n",
        "  # Get the blob (file)\n",
        "  path = os.path.join('catalog', parent, dataset_id.replace('/', '_')) + '.json'\n",
        "  blob = bucket.blob(path)\n",
        "\n",
        "  if not blob.exists():\n",
        "    return 'dataset file not found: ' + path\n",
        "\n",
        "  file_contents = blob.download_as_string().decode()\n",
        "\n",
        "  # Parse the JSON data\n",
        "  entry = json.loads(file_contents)\n",
        "  for link in entry['providers']:\n",
        "    if 'name' in link and link['name'] == 'Google Earth Engine':\n",
        "      catalog_url = link[\"url\"]\n",
        "      break\n",
        "  else:\n",
        "    raise ValueError(f\"No catalog link found for {id}\")\n",
        "  code_sample = _get_dataset_code_sample(catalog_url)\n",
        "  entry[\"code_sample\"] = code_sample\n",
        "  return json.dumps(entry)\n",
        "\n",
        "def _get_image(image_url: str) -\u003e bytes:\n",
        "  \"\"\"Fetches from Earth Engine the content of the given URL as bytes.\"\"\"\n",
        "  response = requests.get(image_url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    return response.content\n",
        "  else:\n",
        "    error_message = f'Error downloading image: {response}'\n",
        "    try:\n",
        "      error_details = (\n",
        "          json.loads(response.content.decode()).get('error', {}).get('message')\n",
        "      )\n",
        "      if error_details:\n",
        "        error_message += f' - {error_details}'\n",
        "    except json.JSONDecodeError:\n",
        "      pass\n",
        "    with debug_output:\n",
        "      print(error_message)\n",
        "    raise ValueError(\"URL %s causes %s\" % (image_url, error_message))\n",
        "\n",
        "def show_layer(python_code: str) -\u003e str:\n",
        "    \"\"\"Execute the given Earth Engine Python client code and add the result to\n",
        "    the map. Returns the status message (success or error message).\"\"\"\n",
        "    Map.layers = Map.layers[:2]\n",
        "    while '\\\\\"' in python_code:\n",
        "      python_code = python_code.replace('\\\\\"', '\"')\n",
        "    command_output.value = f\"show_layer('{python_code}')\"\n",
        "    with debug_output:\n",
        "      print(f'IMAGE:\\n {python_code}\\n')\n",
        "    try:\n",
        "      locals = {}\n",
        "      exec(f\"import ee; im = {python_code}\", {}, locals)\n",
        "      with open(code_editor_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(python_code.replace(\").\", \")\\n.\"))\n",
        "      Map.addLayer(locals['im'])\n",
        "    except Exception as e:\n",
        "      with debug_output:\n",
        "        print(f\"ERROR: {e}\"  )\n",
        "      return str(e)\n",
        "    return 'success'\n",
        "\n",
        "def inner_monologue(thoughts: str) -\u003e str:\n",
        "  \"\"\"Sends the current thinking of the LLM model to the user so that they are\n",
        "  aware of what the model is thinking between function calls.\"\"\"\n",
        "  with debug_output:\n",
        "    print(f'THOUGHTS:\\n {thoughts}\\n')\n",
        "  return 'success'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVpabBfDlTJF"
      },
      "source": [
        "# Functions for textual analysis of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJxTExPhYaOx"
      },
      "outputs": [],
      "source": [
        "def _lat_lon_to_tile(lon, lat, zoom_level):\n",
        "    # Convert latitude and longitude to Mercator coordinates\n",
        "    x_merc = (lon + 180) / 360\n",
        "    y_merc = (1 - math.log(math.tan(math.radians(lat)) + 1 / math.cos(math.radians(lat))) / math.pi) / 2\n",
        "\n",
        "    # Calculate number of tiles\n",
        "    n = 2 ** zoom_level\n",
        "\n",
        "    # Convert to tile coordinates\n",
        "    X = int(x_merc * n)\n",
        "    Y = int(y_merc * n)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "def analyze_image(additional_instructions:str='') -\u003e str:\n",
        "    \"\"\"Returns GenAI image analysis describing the current map image.\n",
        "    Optional additional instructions might be passed to target the analysis\n",
        "    more precisely.\n",
        "    \"\"\"\n",
        "    global map_dirty\n",
        "    if map_dirty:\n",
        "        print('MAP DIRTY')\n",
        "        return 'Map is not ready. Stop further processing and ask for user input'\n",
        "\n",
        "    try:\n",
        "      return _analyze_image(additional_instructions)\n",
        "    except ValueError as e:\n",
        "      return str(e)\n",
        "\n",
        "def _analyze_image(additional_instructions:str='') -\u003e str:\n",
        "    bounds = Map.bounds\n",
        "    s, w = bounds[0]\n",
        "    n, e = bounds[1]\n",
        "    zoom = int(Map.zoom)\n",
        "\n",
        "    min_tile_x, max_tile_y = _lat_lon_to_tile(w, s, zoom)\n",
        "    max_tile_x, min_tile_y = _lat_lon_to_tile(e, n, zoom)\n",
        "    min_tile_x = max(0, min_tile_x)\n",
        "    max_tile_x = min(2**zoom-1, max_tile_x)\n",
        "    min_tile_y = max(0, min_tile_y)\n",
        "    max_tile_y = min(2**zoom-1, max_tile_y)\n",
        "\n",
        "    with debug_output:\n",
        "      if additional_instructions:\n",
        "        print(f\"RUNNING IMAGE ANALYSIS: {additional_instructions}...\\n\")\n",
        "      else:\n",
        "        print(\"RUNNING IMAGE ANALYSIS...\\n\")\n",
        "\n",
        "    layers = list(Map.ee_layer_dict.values())\n",
        "    if not layers:\n",
        "      return 'No data layers loaded'\n",
        "    url_template = layers[-1]['ee_layer'].url\n",
        "    tile_width = 256\n",
        "    tile_height = 256\n",
        "    image_width = (max_tile_x - min_tile_x + 1) * tile_width\n",
        "    image_height = (max_tile_y - min_tile_y + 1) * tile_height\n",
        "\n",
        "    # Create a new blank image\n",
        "    image = PIL.Image.new(\"RGB\", (image_width, image_height))\n",
        "\n",
        "    for y in range(min_tile_y, max_tile_y + 1):\n",
        "      for x in range(min_tile_x, max_tile_x + 1):\n",
        "        tile_url = str.format(url_template, x=x, y=y, z=zoom)\n",
        "        #print(tile_url)\n",
        "        tile_img = PIL.Image.open(io.BytesIO(_get_image(tile_url)))\n",
        "\n",
        "        offset_x = (x - min_tile_x) * tile_width\n",
        "        offset_y = (y - min_tile_y) * tile_height\n",
        "        image.paste(tile_img, (offset_x, offset_y))\n",
        "\n",
        "    width, height = image.size\n",
        "    num_bands = len(image.getbands())\n",
        "    image_array = np.array(image)\n",
        "    image_min = np.min(image_array)\n",
        "    image_max = np.max(image_array)\n",
        "\n",
        "    # Skip an LLM call when we can simply tell that something is wrong.\n",
        "    # (Also, LLMs might hallucinate on uniform images.)\n",
        "    if image_min == image_max:\n",
        "      return (\n",
        "          f'The image tile has a single uniform color with value '\n",
        "          f'{image_min}.'\n",
        "      )\n",
        "\n",
        "    query = \"\"\"You are an objective, precise overhead imagery analyst.\n",
        "Describe what the provided map tile depicts in terms of:\n",
        "\n",
        "1. The colors, textures, and patterns visible in the image.\n",
        "2. The spatial distribution, shape, and extent of distinct features or regions.\n",
        "3. Any notable contrasts, boundaries, or gradients between different areas.\n",
        "\n",
        "Avoid making assumptions about the specific geographic location, time period,\n",
        "or cause of the observed features. Focus solely on the literal contents of the\n",
        "image itself. Clearly indicate which features look natural, which look human-made,\n",
        "and which look like image artifacts. (Eg, a completely straight blue line\n",
        "is unlikely to be a river.)\n",
        "\n",
        "If the image is ambiguous or unclear, state so directly. Do not speculate or\n",
        "hypothesize beyond what is directly visible.\n",
        "\n",
        "Do not address a lack of text or captions in the image. These are provided elsewhere.\n",
        "\n",
        "If the image is of mostly the same color (white, gray, or black) with little\n",
        "contrast, just report that and do not describe the features.\n",
        "\n",
        "Use clear, concise language. Avoid subjective interpretations or analogies.\n",
        "Organize your response into structured paragraphs.\n",
        "\"\"\"\n",
        "    if additional_instructions:\n",
        "      query += additional_instructions\n",
        "    req = {\n",
        "        'parts': [\n",
        "            {\n",
        "                'text': query\n",
        "\n",
        "            },\n",
        "            {'inline_data': image},\n",
        "        ]\n",
        "    }\n",
        "    image_response = image_model.generate_content(req)\n",
        "    try:\n",
        "      with debug_output:\n",
        "        print(f'ANALYSIS RESULT: {image_response.text}\\n')\n",
        "      return image_response.text\n",
        "    except ValueError as e:\n",
        "      with debug_output:\n",
        "        print(f'UNEXPECTED IMAGE RESPONSE: {e}')\n",
        "        print(image_response)\n",
        "      breakpoint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFrNINUCQgW4"
      },
      "source": [
        "# Load EE Dataset Embeddings\n",
        "This will take a few minutes the first time. The second time the cell is run it will be only ~10s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kP8dZ2L6QcAD"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.base import Embeddings\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.indexes.vectorstore import VectorstoreIndexCreator\n",
        "from langchain.schema import Document\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "def rate_limit(max_per_minute):\n",
        "  period = 60 / max_per_minute\n",
        "  while True:\n",
        "    before = time.time()\n",
        "    yield\n",
        "    after = time.time()\n",
        "    elapsed = after - before\n",
        "    sleep_time = max(0, period - elapsed)\n",
        "    if sleep_time \u003e 0:\n",
        "      print(f'Sleeping {sleep_time:.1f} seconds')\n",
        "      time.sleep(sleep_time)\n",
        "\n",
        "class VertexEmbeddings(Embeddings):\n",
        "\n",
        "  def __init__(self, model, *, requests_per_minute=15):\n",
        "    self.model = model\n",
        "    self.requests_per_minute = requests_per_minute\n",
        "\n",
        "  def embed_documents(self, texts):\n",
        "    limiter = rate_limit(self.requests_per_minute)\n",
        "    results = []\n",
        "    docs = list(texts)\n",
        "\n",
        "    while docs:\n",
        "      # Working in batches of 2 because the API apparently won't let\n",
        "      # us send more than 2 documents per request to get embeddings.\n",
        "      head, docs = docs[:2], docs[2:]\n",
        "      chunk = self.model.get_embeddings(head)\n",
        "      results.extend(chunk)\n",
        "      next(limiter)\n",
        "\n",
        "    return [r.values for r in results]\n",
        "\n",
        "  def embed_query(self, text):\n",
        "    single_result = self.embed_documents([text])\n",
        "    return single_result[0]\n",
        "\n",
        "jsonl_path = f'catalog_summaries.jsonl'\n",
        "embedding_model = TextEmbeddingModel.from_pretrained(\"google/text-embedding-004\")\n",
        "embedding = VertexEmbeddings(embedding_model, requests_per_minute=600)\n",
        "\n",
        "def load_docs_from_jsonl(file_path):\n",
        "  docs = []\n",
        "  with open(file_path, 'r') as jsonl_file:\n",
        "    for line in jsonl_file:\n",
        "      data = json.loads(line)\n",
        "      obj = Document(**data)\n",
        "      docs.append(obj)\n",
        "  return docs\n",
        "\n",
        "# Create the embeddings only if the embeddings aren't already defined.\n",
        "if not ('index' in globals() or 'index' in locals()):\n",
        "  if os.path.isfile(jsonl_path):\n",
        "    print(f\"Found existing jsonl index at ${jsonl_path}\")\n",
        "    documents = load_docs_from_jsonl(jsonl_path)\n",
        "    # load the dates as datetime objects\n",
        "    for i in range(len(documents)):\n",
        "      documents[i].metadata['temporal'] = [dateutil.parser.parse(date_str) if date_str is not None else None for date_str in documents[i].metadata['temporal']]\n",
        "    index = VectorstoreIndexCreator(embedding=embedding).from_documents(documents)\n",
        "  else:\n",
        "    raise ValueError(f\"No catalog found at {jsonl_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd7-gHg-8qsK"
      },
      "source": [
        "## Dataset filtering functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-SMNCbGEU5d"
      },
      "outputs": [],
      "source": [
        "import shapely\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from typing import Optional, Union\n",
        "\n",
        "def _temporal_bounds_intersect(tbox1, tbox2):\n",
        "    start1, end1 = tbox1\n",
        "    start2, end2 = tbox2\n",
        "\n",
        "    # Convert dates to datetimes\n",
        "    start_date_to_start_datetime = lambda start_date: datetime.datetime(start_date.year, start_date.month, start_date.day, 0, 0, 0) if isinstance(start_date, datetime.date) else start_date\n",
        "    end_date_to_end_datetime = lambda end_date: start_date_to_start_datetime(end_date) + datetime.timedelta(days=1) if isinstance(end_date, datetime.date) else end_date\n",
        "\n",
        "    start1 = start_date_to_start_datetime(start1).timestamp() if start1 is not None else float('-inf')\n",
        "    start2 = start_date_to_start_datetime(start2).timestamp() if start2 is not None else float('-inf')\n",
        "    end1 = end_date_to_end_datetime(end1).timestamp() if end1 is not None else float('inf')\n",
        "    end2 = end_date_to_end_datetime(end2).timestamp() if end2 is not None else float('inf')\n",
        "\n",
        "    return not (start1 \u003e end2 or start2 \u003e end1)\n",
        "\n",
        "def _spatial_bounds_intersect(sbox1, sbox2):\n",
        "  return shapely.box(*sbox1).intersects(shapely.box(*sbox2))\n",
        "\n",
        "def _raise_error(e):\n",
        "  \"\"\"Utility to support error raising in python expressions\"\"\"\n",
        "  raise e\n",
        "\n",
        "float_to_int_without_truncation = lambda x: int(x) if x == int(x) else _raise_error(ValueError(f\"{x} is not an integer\"))\n",
        "\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import base64\n",
        "\n",
        "\n",
        "def _image_to_html(img_url, width=100, height=100):\n",
        "    # Download image\n",
        "    response = requests.get(img_url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "\n",
        "    # Convert image to base64\n",
        "    buffer = BytesIO()\n",
        "    img.save(buffer, format='PNG')\n",
        "    img_str = base64.b64encode(buffer.getvalue()).decode('ascii')\n",
        "\n",
        "    # Create HTML image tag\n",
        "    html_img = f'\u003cimg src=\"data:image/png;base64,{img_str}\" width=\"{width}\" height=\"{height}\"\u003e'\n",
        "    return html_img\n",
        "\n",
        "def _build_dataset_widget(id: str):\n",
        "  description = get_dataset_description(id)\n",
        "  print(description)\n",
        "  entry = json.loads(description)\n",
        "  # get image url\n",
        "  for link in entry['links']:\n",
        "    if 'rel' in link and link['rel'] == 'preview':\n",
        "      assert link['type'] == 'image/png'\n",
        "      image_url = link['href']\n",
        "      break\n",
        "  else:\n",
        "    raise ValueError(f\"No preview image found for {id}\")\n",
        "  # get EE catalog URL\n",
        "  for link in entry['providers']:\n",
        "    if 'name' in link and link['name'] == 'Google Earth Engine':\n",
        "      catalog_url = link[\"url\"]\n",
        "      break\n",
        "  else:\n",
        "    raise ValueError(f\"No catalog link found for {id}\")\n",
        "  image = _image_to_html(image_url)\n",
        "  title = entry['title']\n",
        "  temporal = str(entry['extent']['temporal']['interval'])\n",
        "  keywords = \", \".join(entry['keywords'])\n",
        "  id_table_entry = f'\u003ca href=\"{catalog_url}\" target=\"_blank\"\u003e{id}\u003c/a\u003e'\n",
        "  return pd.Series({'Image': image, \"ID\": id_table_entry, \"Title\": title, \"Temporal Span\": temporal, \"Keywords\": keywords})\n",
        "\n",
        "def build_dataset_widget(ids: list[str]):\n",
        "  return pd.DataFrame([_build_dataset_widget(id) for id in ids])\n",
        "\n",
        "def assert_condition(condition, exp):\n",
        "  assert condition, f\"Assertion failed, {condition}\"\n",
        "  return exp\n",
        "\n",
        "def find_dataset(query: str, results: int = 4, threshold: float = 0.7, spatial: Optional[list[float]]=None, temporal: Optional[list[Optional[list[int]]]]=None) -\u003e pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Retrieve relevant dataset from the Earth Engine data catalog.\n",
        "\n",
        "  query: str. The kind of data being searched for. ie 'population' or 'Cheese Futures'.\n",
        "  results: int. The number of datasets to return. 4 is recommended.\n",
        "  threshold: float. The maximum dot product between the query and catalog\n",
        "    embeddings. Recommended 0.7.\n",
        "  spatial: Optional[list[float]]. The spatial bounding box for the query, in the\n",
        "    format [lon1, lat1, lon2, lon2]. If None then no spatial filter is appled.\n",
        "  temporal: Optional[list[Optional[list[int]]]]. If provided, temporal\n",
        "    constraints are provided as a list of two int lists following the structure\n",
        "    [[year, month, day], [year, month, day]]. A none can be used to set no\n",
        "    start or end date. For example [None, [2022,12,31]] will return all datasets\n",
        "    that have data before 2022-12-31.\n",
        "  \"\"\"\n",
        "  results = float_to_int_without_truncation(results)\n",
        "  if temporal is not None:\n",
        "    temporal = [datetime.date(*list(map(float_to_int_without_truncation, temporal[0]))) if temporal[0] is not None else None,\n",
        "                datetime.date(*list(map(float_to_int_without_truncation, temporal[1]))) if temporal[1] is not None else None]\n",
        "    if temporal[0] is not None and temporal[1] is not None and temporal[0] \u003e temporal[1]:\n",
        "      raise ValueError(f\"Temporal bounds must be in chronological order: {temporal}\")\n",
        "\n",
        "  # Get the relevant dataset\n",
        "  similar_datasets = index.vectorstore.similarity_search_with_score(query, llm=llm, k=len(documents))\n",
        "  # Filter by relevance threshold\n",
        "  filtered = list(filter(lambda doc: doc[1] \u003c= threshold, similar_datasets))\n",
        "  # Filter by time\n",
        "  filtered = list(filter(lambda doc: _temporal_bounds_intersect(doc[0].metadata['temporal'], temporal) if temporal is not None else True, filtered))\n",
        "  # Remove community catalog entries\n",
        "  filtered = list(filter(lambda doc: not doc[0].metadata['id'].startswith(\"projects/\"), filtered))\n",
        "  # Filter by space\n",
        "  filtered = list(filter(lambda doc: assert_condition(len(doc[0].metadata['spatial']) == 1, _spatial_bounds_intersect(doc[0].metadata['spatial'][0], spatial)) if spatial is not None else True, filtered))\n",
        "  # Select the top k results\n",
        "  filtered = filtered[:min(results, len(filtered))]\n",
        "  # Format output\n",
        "  outputs = [[dataset[0].metadata['title'], dataset[0].metadata['id'], dataset[0].page_content] for dataset in filtered]\n",
        "  update_dataset_widget(build_dataset_widget([output[1] for output in outputs]))\n",
        "  return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9aHH0wrlZdd"
      },
      "source": [
        "# Function for scoring how well image analysis corresponds to the user query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9tEDtbkYvCi"
      },
      "outputs": [],
      "source": [
        "# Note that we ask for the score outside of the main agent chat to keep\n",
        "# the scoring more objective.\n",
        "\n",
        "scoring_system_prompt = \"\"\"\n",
        "After looking at the user query and the map tile analysis, start\n",
        "your answer with a number between 0 and 1 indicating how relevant\n",
        "the image is as an answer to the query. (0=irrelevant, 1=perfect answer)\n",
        "\n",
        "Make sure you have enough justification to definitively declare the analysis\n",
        "relevant - it's better to give a false negative than a false positive. However,\n",
        "the image analysis identifies specific matching landmarks (eg, the\n",
        "the outlines of Manhattan island for a request to show NYC), believe it.\n",
        "\n",
        "Do not assume  too much (eg, that the presence of green doesn't by itself mean the\n",
        "image shows forest); attempt to find multiple (at least three) independent\n",
        "lines of evidence before declaring victory and cite all these lines of evidence\n",
        "in your response.\n",
        "\n",
        "Be very, very skeptical - look for specific features that match only the query\n",
        "and nothing else (eg, if the query looks for a river, a completely straight blue\n",
        "line is unlikely to be a river). Think about what size the features are based on\n",
        "the zoom level and whether this size matches the feature size expected from\n",
        "first principles.\n",
        "\n",
        "If there is ambiguity or uncertainty, express it in your analysis and\n",
        "lower the score accordingly. If the image analysis is inconclusive, try zooming\n",
        "out to make sure you are looking at the right spot. Do not reduce the score if\n",
        "the analysis does not mention visualization parameters - they are just given for\n",
        "your reference. The image might show an area slightly larger than requested -\n",
        "this is okay, do not reduce the score on this account.\n",
        "\"\"\"\n",
        "\n",
        "def score_response(query: str, visualization_parameters: str, analysis: str) -\u003e str:\n",
        "    \"\"\"Returns how well the given analysis describes a map tile returned for\n",
        "    the given query. The analysis starts with a number between 0 and 1.\n",
        "\n",
        "    Arguments:\n",
        "      query: user-specified query\n",
        "      visualization_parameters: description of the bands used and visualization\n",
        "        parameters applied to the map tile\n",
        "      analysis: the textual description of the map tile\n",
        "    \"\"\"\n",
        "    with debug_output:\n",
        "      print(f\"VIZ PARAMS: {visualization_parameters}\\n\")\n",
        "    question = (\n",
        "        f\"\"\"For user query {query} please score the following analysis:\n",
        "       {analysis}. The answer must start with a number between 0 and 1.\"\"\")\n",
        "    if visualization_parameters:\n",
        "      question += (\n",
        "          f\"\"\"Do not assume that common bands or visualization\n",
        "          parameters should have been used, as the visualization used the\n",
        "          following parameters: {visualization_parameters}\"\"\")\n",
        "\n",
        "    result = analysis_model.ask(question)\n",
        "    global iteration\n",
        "    with debug_output:\n",
        "      print(f'SCORE #{iteration}:\\n {result}\\n')\n",
        "    iteration += 1\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcOLx1FKliit"
      },
      "source": [
        "# Main prompt for the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zf1Hmj6BY2lx"
      },
      "outputs": [],
      "source": [
        "system_prompt = f\"\"\"\n",
        "The client is running in a Python notebook with a geemap Map displayed. The\n",
        "client also has a code editor that's initialized and authenticated with\n",
        "earthengine. When given a task or a question. Start by making a plan of how you\n",
        "will approach solving it. Important: Only use the map if the user stated that\n",
        "they want to see or visualize data.\n",
        "\n",
        "When composing Python code for the map, do not use getMapId - just return the\n",
        "single-line layer definition like 'ee.Image(\"USGS/SRTMGL1_003\")' that we will\n",
        "pass to Map.addLayer(). Do not escape quotation marks in Python code.\n",
        "\n",
        "Be sure to use Python, not Javascript, syntax for keyword parameters in\n",
        "Python code (that is, \"function(arg=value)\") Using the provided functions,\n",
        "respond to the user command following below (or respond why it's not possible).\n",
        "If you get an Earth Engine error, attempt to fix it and then try again.\n",
        "\n",
        "Before you choose a dataset, think about what kind of dataset would be most\n",
        "suitable for the query. When using the map also think about what zoom level\n",
        "would be suitable for the query, keeping in mind that for high-resolution\n",
        "image collections higher zoom levels are better to speed up tile loading. You\n",
        "can search for available datasets using the find_dataset functions. For example\n",
        "to find datasets that have information about burn scars between 2020 and 2022,\n",
        "you can use find_dataset('Burn Scars', temporal=[[2020,1,1], [2022,12,31]]).\n",
        "\n",
        "Once you have chosen a dataset, read its description using the provided function\n",
        "to see what spatial and temporal range it covers, what bands it has, as well as\n",
        "to find the recommended visualization parameters. Explain using the inner\n",
        "monlogue function why you chose a specific dataset, zoom level and map location.\n",
        "\n",
        "Use Landsat Collection 2, not Landsat Collection 1 ids. If you are getting\n",
        "repeated errors when filtering by a time range, read the dataset description\n",
        "to confirm that the dataset has data for the selected range.\n",
        "\n",
        "When visualizing on the map, prefer mosaicing image collections using the\n",
        "mosaic() function, don't get individual images from collections via 'first()'.\n",
        "Choose a tile size and zoom level that will ensure the tile has enough pixels\n",
        "in it to avoid graininess, but not so many that processing becomes very\n",
        "expensive. Do not use wide date ranges with collections that have many images,\n",
        "but remember that Landsat and Sentinel-2 have revisit period of several days.\n",
        "Do not use sample locations - try to come up with actual locations that are\n",
        "relevant to the request.\n",
        "\n",
        "IF YOU ARE ASKED TO PROVIDE INFORMATION ABOUT A DATASET, DO NOT MAP THE\n",
        "DATASET UNLESS THE USER REQUESTS THAT YOU MAP THE DATASET.\n",
        "\n",
        "Important: after using the set_center() function, just say that you have called\n",
        "this function and wait for the user to hit enter, after which you should\n",
        "continue answering the original request. This will make sure the map is updated\n",
        "on the client side.\n",
        "\n",
        "Once the map is updated and the user told you to proceed, call the analyze_image\n",
        "function() to describe the image for the same location that will be shown in\n",
        "geemap. If you pass additional instructions to analyze_image(), do not disclose\n",
        "what the image is supposed to be to discourage hallucinations - you can only tell\n",
        "the analysis function to pay attention to specific areas (eg, center or top left)\n",
        "or shapes (eg, a line at the bottom) in the image. You can also tell the analysis\n",
        "function about the chosen bands, color palette and min/max visualization\n",
        "parameters, if any, to help it interpret the colors correctly. If the image\n",
        "turns out to be uniform in color with no features,\n",
        "use min/max visualization parameters to enhance contrast.\n",
        "\n",
        "Frequently call the inner_monologue() functions to tell the user about your\n",
        "current thought process. This is a good time to reflect if you have been running\n",
        "into repeated errors of the same kind, and if so, to try a different approach.\n",
        "\n",
        "When you are done, call the score_response() function to evaluate the analysis.\n",
        "You can also tell the scoring function about the chosen bands, color palette\n",
        "and min/max visualization parameters, if any. If the analysis score is below\n",
        "{target_score},\n",
        "keep trying to find and show a better image. You might have to change the dataset,\n",
        "map location, zoom level, date range, bands, or other parameters - think about\n",
        "what went wrong in the previous attempt and make the change that's most likely\n",
        "to improve the score.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP_iUvcfwZGG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHOlWd2oln7t"
      },
      "source": [
        "# Class for LLM chat with function calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzab3ZUEY4-v"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "gemini_tools=[\n",
        "        set_center,\n",
        "        show_layer,\n",
        "        analyze_image,\n",
        "        inner_monologue,\n",
        "        get_dataset_description,\n",
        "        score_response,\n",
        "        find_dataset,\n",
        "]\n",
        "\n",
        "class Gemini():\n",
        "  \"\"\"Gemini LLM.\"\"\"\n",
        "\n",
        "  def __init__(self, system_prompt, tools=None):\n",
        "    if not tools:\n",
        "      tools = []\n",
        "    self._text_model = genai.GenerativeModel(\n",
        "      model_name='gemini-1.5-pro-latest',\n",
        "      tools=tools\n",
        "    )\n",
        "\n",
        "    initial_messages = glm.Content(\n",
        "        role='model',\n",
        "        parts=[glm.Part(text=system_prompt)])\n",
        "    self._chat_proxy = self._text_model.start_chat(\n",
        "        history=initial_messages, enable_automatic_function_calling=True)\n",
        "\n",
        "  def ask(self, question, temperature=0):\n",
        "    while True:\n",
        "      condition = ''\n",
        "      try:\n",
        "        sleep_duration = 10\n",
        "        response = self._text_model.generate_content(question + condition)\n",
        "        return response.text\n",
        "      except genai.types.generation_types.StopCandidateException as e:\n",
        "          if glm.Candidate.FinishReason.RECITATION == e.args[0].finish_reason:\n",
        "            condition = (\n",
        "                'Previous attempt returned a RECITATION error. '\n",
        "                'Rephrase the answer to avoid it.')\n",
        "          with chat_output:\n",
        "            command_input.description = 'üÜÅ'\n",
        "          time.sleep(1)\n",
        "          with chat_output:\n",
        "            command_input.description = 'ü§î'\n",
        "          continue\n",
        "      except (\n",
        "          google.api_core.exceptions.TooManyRequests,\n",
        "          google.api_core.exceptions.DeadlineExceeded\n",
        "      ):\n",
        "        with debug_output:\n",
        "          command_input.description = 'üí§'\n",
        "        time.sleep(sleep_duration)\n",
        "        continue\n",
        "      except ValueError as e:\n",
        "        with debug_output:\n",
        "          print(f'Response {response} led to error: {e}')\n",
        "        breakpoint()\n",
        "        i = 1\n",
        "\n",
        "  def chat(self, question: str, temperature=0) -\u003e str:\n",
        "    \"\"\"Adds a question to the ongoing chat session.\"\"\"\n",
        "    # Always delay a bit to reduce the chance for rate-limiting errors.\n",
        "    time.sleep(1)\n",
        "    condition = ''\n",
        "    sleep_duration = 10\n",
        "    while True:\n",
        "      response = ''\n",
        "      try:\n",
        "        response = self._chat_proxy.send_message(\n",
        "            question + condition,\n",
        "            generation_config={\n",
        "                'temperature': temperature,\n",
        "                # Use a generous but limited output size to encourage in-depth\n",
        "                # replies.\n",
        "                'max_output_tokens': 5000,\n",
        "            }\n",
        "        )\n",
        "        if not response.parts:\n",
        "          raise ValueError(\n",
        "              'Cannot get analysis with reason'\n",
        "              f' {response.candidates[0].finish_reason.name}, terminating'\n",
        "          )\n",
        "      except genai.types.generation_types.StopCandidateException as e:\n",
        "          if glm.Candidate.FinishReason.RECITATION == e.args[0].finish_reason:\n",
        "            condition = (\n",
        "                'Previous attempt returned a RECITATION error. '\n",
        "                'Rephrase the answer to avoid it.')\n",
        "          with chat_output:\n",
        "            command_input.description = 'üÜÅ'\n",
        "          time.sleep(1)\n",
        "          with chat_output:\n",
        "            command_input.description = 'ü§î'\n",
        "          continue\n",
        "      except (\n",
        "            google.api_core.exceptions.TooManyRequests,\n",
        "            google.api_core.exceptions.DeadlineExceeded\n",
        "        ):\n",
        "          with debug_output:\n",
        "            command_input.description = 'üí§'\n",
        "          time.sleep(10)\n",
        "          continue\n",
        "      try:\n",
        "        return response.text\n",
        "      except ValueError as e:\n",
        "       with debug_output:\n",
        "        print(f'Response {response} led to the error {e}')\n",
        "\n",
        "model = Gemini(system_prompt, gemini_tools)\n",
        "analysis_model = Gemini(scoring_system_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J_I_PsdlucV"
      },
      "source": [
        "# UI functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y64VbasPY-UP"
      },
      "outputs": [],
      "source": [
        "def set_cursor_waiting():\n",
        "    js_code = \"\"\"\n",
        "    document.querySelector('body').style.cursor = 'wait';\n",
        "    \"\"\"\n",
        "    display(HTML(f\"\u003cscript\u003e{js_code}\u003c/script\u003e\"))\n",
        "\n",
        "def set_cursor_default():\n",
        "    js_code = \"\"\"\n",
        "    document.querySelector('body').style.cursor = 'default';\n",
        "    \"\"\"\n",
        "    display(HTML(f\"\u003cscript\u003e{js_code}\u003c/script\u003e\"))\n",
        "\n",
        "def on_submit(widget):\n",
        "    global map_dirty\n",
        "    map_dirty = False\n",
        "    command_input.description = '‚ùì'\n",
        "    command = widget.value\n",
        "    if not command:\n",
        "      command = 'go on'\n",
        "    with chat_output:\n",
        "      print('\u003e ' + command + '\\n')\n",
        "    if command != 'go on':\n",
        "      with debug_output:\n",
        "        print('\u003e ' + command + '\\n')\n",
        "    widget.value = ''\n",
        "    set_cursor_waiting()\n",
        "    command_input.description = 'ü§î'\n",
        "    response = model.chat(command, temperature=0)\n",
        "    if map_dirty:\n",
        "      command_input.description = 'üôè'\n",
        "    else:\n",
        "      command_input.description = '‚ùì'\n",
        "    set_cursor_default()\n",
        "    response = response.strip()\n",
        "    if not response:\n",
        "      response = ''\n",
        "    with chat_output:\n",
        "        print(response + '\\n')\n",
        "    command_input.value = ''\n",
        "\n",
        "command_input.on_submit(on_submit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUahB4melyxt"
      },
      "source": [
        "# UI layout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byEddbEPMfUU"
      },
      "outputs": [],
      "source": [
        "def build_frontend(show_debug_column=False):\n",
        "  # Arrange the chat history and input in a vertical box\n",
        "  chat_ui = widgets.VBox([chat_output], layout=widgets.Layout(width='400px'))\n",
        "\n",
        "  chat_output.layout = widgets.Layout(width='400px')  # Fixed width for the left control\n",
        "  Map.layout = widgets.Layout(width='600px')\n",
        "\n",
        "  # labels\n",
        "  code_viewer_label = widgets.Label(\"Code Generated by Agent\")\n",
        "  dataset_label = widgets.Label(\"Datasets Discovered by Agent\")\n",
        "  map_label = widgets.Label(\"Map\")\n",
        "\n",
        "\n",
        "  top_row = widgets.HBox([chat_output, code_editor, code_viewer_label])\n",
        "  bottom_row = widgets.HBox([Map, dataset_widget])\n",
        "\n",
        "  ui_widgets = [top_row, command_input, bottom_row]\n",
        "  ui_widgets = ui_widgets + [debug_output] if show_debug_column else ui_widgets\n",
        "  return widgets.VBox(ui_widgets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-JFBG2aMrSD"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YUIQVyJ8VJc"
      },
      "outputs": [],
      "source": [
        "# Display the layout\n",
        "ui = build_frontend(show_debug_column = False)\n",
        "display(ui)\n",
        "# print('‚ùì = waiting for user input')\n",
        "# print('üôè = waiting for user to hit enter after calling set_center()')\n",
        "# print('ü§î = thinking')\n",
        "# print('üí§ = sleeping due to retries')\n",
        "# print('üÜÅ = Gemini recitation error')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "b09aYpe5k4W0",
        "ESeVud7llELN",
        "OUxyUVnAlNeI",
        "yVpabBfDlTJF",
        "q9aHH0wrlZdd",
        "JcOLx1FKliit",
        "uHOlWd2oln7t",
        "7J_I_PsdlucV"
      ],
      "name": "external_applied_sciences_EE_dataset_search_agent.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
