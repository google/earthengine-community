{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Earth Engine Companion\n",
        "\n",
        "**USING THIS AGENT IS UNSAFE**. It directly runs LLM-produced code, and thus\n",
        "should only be used for demonstration purposes. However, Colab serves as\n",
        "a moderately effective sandbox - the damage would be limited to whatever\n",
        "this notebook has access to.\n",
        "\n",
        "## Configuration\n",
        "\n",
        "To run with the sample task (see `task` variable below),\n",
        "[obtain a Gemini API key](https://ai.google.dev/gemini-api/docs/api-key)\n",
        "and save it into a [Colab secret](https://colab.sandbox.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) named \"GOOGLE_API_KEY\".\n",
        "\n",
        "Run the notebook, then scroll to the end. You will see an empty text area\n",
        "and the task definition under it. Hit Enter in the task defintion input box\n",
        "to start processing.\n",
        "\n",
        "By default, the Gemini API is used. You can switch to OpenAI, Anthropic, or DeepSeek\n",
        "APIs by uncommenting the relevant LLM class in the last cell. You will also\n",
        "need to save ANTHROPIC_API_KEY, OPENAI_API_KEY, or DEEPSEEK_API_KEY secrets.\n",
        "\n",
        "## Related work\n",
        "\n",
        "A similar non-Earth-Engine-specific notebook is available [here](https://github.com/google/earthengine-community/blob/master/experimental/functionsmith/functionsmith.ipynb).\n",
        "\n",
        "## Attribution\n",
        "\n",
        "EE Companion and the functionsmith package were written by Simon Ilyushchenko (simonf@google.com). I am grateful to Renee Johnston and other Googlers for implementation advice, as well as to Earth Engine expert advisors Jeffrey Cardille, Erin Trochim, Morgan Crowley, and Samapriya Roy, who helped me choose the right training tasks."
      ],
      "metadata": {
        "id": "hqHymKLj5clL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install functionsmith"
      ],
      "metadata": {
        "id": "35c4WBO-KvoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "nZ5OBZ5xypYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import copy\n",
        "import enum\n",
        "import inspect\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from typing import Callable\n",
        "\n",
        "import google.colab\n",
        "from google.colab import userdata\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML, Javascript\n",
        "\n",
        "from functionsmith import code_parser\n",
        "from functionsmith import executor\n",
        "from functionsmith import llm\n"
      ],
      "metadata": {
        "id": "OGciaLzqyqs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import geemap\n",
        "ee.Authenticate(scopes=['https://www.googleapis.com/auth/earthengine.readonly'])\n",
        "ee.Initialize(project=userdata.get('EE_PROJECT_ID'))\n",
        "\n",
        "Map = geemap.Map()\n",
        "Map.add_basemap(\"Esri.WorldImagery\", False)\n",
        "Map.add(\"layer_manager\")\n",
        "\n",
        "from google.cloud import storage\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.get_bucket('earthengine-stac')\n",
        "\n",
        "# Hardcode the name of a dataset from the community catalog used in one\n",
        "# of the sample tasks.\n",
        "hydrolakes_dataset_id = 'projects/sat-io/open-datasets/HydroLakes/lake_poly_v10'"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XcWwjpOvgD5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_description(dataset_id: str) -> str:\n",
        "  \"\"\"Fetches JSON STAC description for the given Earth Engine dataset id.\"\"\"\n",
        "  if not dataset_id:\n",
        "    return 'ERROR: please provide dataset_id'\n",
        "  with io_manager._output_area:\n",
        "    print(f'\\nLOOKING UP {dataset_id}')\n",
        "\n",
        "  if dataset_id == hydrolakes_dataset_id:\n",
        "    return hydrolakes_schema\n",
        "\n",
        "  parent = dataset_id.split('/')[0]\n",
        "\n",
        "  # Get the blob (file)\n",
        "  path = os.path.join('catalog', parent, dataset_id.replace('/', '_')) + '.json'\n",
        "  blob = bucket.blob(path)\n",
        "\n",
        "  if not blob.exists():\n",
        "    with io_manager._output_area:\n",
        "      print(f'LOOKUP FAILED - NO SUCH DATASET\\n{STARS}')\n",
        "    return 'No such dataset'\n",
        "\n",
        "  file_contents = blob.download_as_string().decode()\n",
        "  with io_manager._output_area:\n",
        "    print(f'LOOKUP SUCCESSFUL\\n{STARS}')\n",
        "  return file_contents"
      ],
      "metadata": {
        "id": "Lxuza6PXqIpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# System prompt"
      ],
      "metadata": {
        "id": "UteXTs9zyy82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_instruction=\"\"\"\n",
        "You are an AI assistant designed to solve geospatial problems using Google Earth\n",
        "Engine and Python. **Crucially, you must operate in an evolutionary,\n",
        "step-by-step manner.**\n",
        "\n",
        "**Your core directives are:**\n",
        "\n",
        "1.  **Decomposition:** Analyze the user's request and **break it down into the\n",
        "smallest possible logical sub-tasks.**\n",
        "\n",
        "2.  **Incremental Execution:** Address **only one sub-task per turn.**\n",
        "Propose the next step only after the current one is successfully completed\n",
        "and verified.\n",
        "\n",
        "3.  **Minimal Code:** For each step, write the **absolute minimum amount of\n",
        "Python code** required to achieve that single sub-task.\n",
        "\n",
        "4.  **Verification:** **Explicitly verify the result of each step** before\n",
        "moving on. This might involve printing intermediate values, checking counts\n",
        "(`.size().getInfo()`), examining properties (`.getInfo()`), or adding temporary\n",
        "layers to the map for visual confirmation.\n",
        "\n",
        "5.  **Explanation:** **Clearly state the goal of the current step** before\n",
        "presenting the code. After execution, briefly explain the result and state\n",
        "the goal for the *next* step.\n",
        "\n",
        "6.  **No Premature Solutions:** **Do not provide code that attempts to solve\n",
        "multiple steps or the entire problem at once.**\n",
        "\n",
        "7.  **Context Awareness:** Remember that variables are **not persistent**\n",
        "between code executions. Reload data or recalculate intermediate results\n",
        "as needed in each step.\n",
        "\n",
        "**Example Interaction Flow:**\n",
        "\n",
        "*   User provides a task.\n",
        "*   You state the first small step (e.g., \"First, I need to find and examine\n",
        "the relevant dataset. I will fetch its description.\").\n",
        "*   You provide *only* the code for that step (e.g., `print(get_dataset_description(...))`).\n",
        "*   User executes the code.\n",
        "*   You analyze the result, state the next small step (e.g., \"Okay, the dataset\n",
        "looks suitable. Now I will load it as a FeatureCollection.\"), provide the minimal\n",
        "code for *that* step, and so on.\n",
        "\n",
        "Adhere strictly to this incremental and verifiable process.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2JQtDWo7WgJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task"
      ],
      "metadata": {
        "id": "8iUVE9nty8r-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = ''\n",
        "\n",
        "if False:\n",
        "  task = 'Show me something interesting, unexpected, and uplifting. Explain why you chose what you chose.'\n",
        "\n",
        "if False:\n",
        "  task = 'Zoom in to a random midsize city and display a recent Sentinel-2 monthly mosaic with good visualization. Do not use filterBounds()'\n",
        "\n",
        "if False:\n",
        "  task = \"Compute the area of Belgium by querying the WM/geoLab/geoBoundaries/600/ADM0 dataset in Earth Engine. Show the boundaries on geemap and zoom in on them.\"\n",
        "\n",
        "# The schema for the Hydrolakes dataset, which is not present in the main EE catalog.\n",
        "hydrolakes_schema = \"\"\"\n",
        "Hylak_id\tUnique lake identifier. Values range from 1 to 1,427,688.\n",
        "Lake_name\tName of lake or reservoir. This field is currently only populated for lakes with an area of at least 500 km2; for large reservoirs where a name was available in the GRanD database; and for smaller lakes where a name was available in the GLWD database.\n",
        "Country\tCountry that the lake (or reservoir) is located in. International or transboundary lakes are assigned to the country in which its corresponding lake pour point is located and may be arbitrary for pour points that fall on country boundaries.\n",
        "Continent\tContinent that the lake (or reservoir) is located in. Geographic continent: Africa, Asia, Europe, North America, South America, or Oceania (Australia and Pacific Islands)\n",
        "Poly_src\tSource of original lake polygon: CanVec; SWBD; MODIS; NHD; ECRINS; GLWD; GRanD; or Other More information on these data sources can be found in Table 1.\n",
        "Lake_type\tIndicator for lake type: 1: Lake 2: Reservoir 3: Lake control (i.e. natural lake with regulation structure) Note that the default value for all water bodies is 1, and only those water bodies explicitly identified as other types (mostly based on information from the GRanD database) have other values; hence the type ‘Lake’ also includes all unidentified smaller human-made reservoirs and regulated lakes.\n",
        "Grand_id\tID of the corresponding reservoir in the GRanD database, or value 0 for no corresponding GRanD record. This field can be used to join additional attributes from the GRanD database.\n",
        "Lake_area\tLake surface area (i.e. polygon area), in square kilometers.\n",
        "Shore_len\tLength of shoreline (i.e. polygon outline), in kilometers.\n",
        "Shore_dev\tShoreline development, measured as the ratio between shoreline length and the circumference of a circle with the same area. A lake with the shape of a perfect circle has a shoreline development of 1, while higher values indicate increasing shoreline complexity.\n",
        "Vol_total\tTotal lake or reservoir volume, in million cubic meters (1 mcm = 0.001 km3). For most polygons, this value represents the total lake volume as estimated using the geostatistical modeling approach by Messager et al. (2016). However, where either a reported lake volume (for lakes ≥ 500 km2) or a reported reservoir volume (from GRanD database) existed, the total volume represents this reported value. In cases of regulated lakes, the total volume represents the larger value between reported reservoir and modeled or reported lake volume. Column ‘Vol_src’ provides additional information regarding these distinctions.\n",
        "Vol_res\tReported reservoir volume, or storage volume of added lake regulation, in million cubic meters (1 mcm = 0.001 km3). 0: no reservoir volume\n",
        "Vol_src\t1: ‘Vol_total’ is the reported total lake volume from literature 2: ‘Vol_total’ is the reported total reservoir volume from GRanD or literature 3: ‘Vol_total’ is the estimated total lake volume using the geostatistical modeling approach by Messager et al. (2016)\n",
        "Depth_avg\tAverage lake depth, in meters. Average lake depth is defined as the ratio between total lake volume (‘Vol_total’) and lake area (‘Lake_area’).\n",
        "Dis_avg\tAverage long-term discharge flowing through the lake, in cubic meters per second. This value is derived from modeled runoff and discharge estimates provided by the global hydrological model WaterGAP, downscaled to the 15 arc-second resolution of HydroSHEDS (see section 2.2 for more details) and is extracted at the location of the lake pour point. Note that these model estimates contain considerable uncertainty, in particular for very low flows. -9999: no data as lake pour point is not on HydroSHEDS landmask\n",
        "Res_time\tAverage residence time of the lake water, in days. The average residence time is calculated as the ratio between total lake volume (‘Vol_total’) and average long-term discharge (‘Dis_avg’). Values below 0.1 are rounded up to 0.1 as shorter residence times seem implausible (and likely indicate model errors). -1: cannot be calculated as ‘Dis_avg’ is 0 -9999: no data as lake pour point is not on HydroSHEDS landmask\n",
        "Elevation\tElevation of lake surface, in meters above sea level. This value was primarily derived from the EarthEnv-DEM90 digital elevation model at 90 m pixel resolution by calculating the majority pixel elevation found within the lake boundaries. To remove some artefacts inherent in this DEM for northern latitudes, all lake values that showed negative elevation for the area north of 60°N were substituted with results using the coarser GTOPO30 DEM of USGS at 1 km pixel resolution, which ensures land surfaces ≥0 in this region. Note that due to the remaining uncertainties in the EarthEnv-DEM90 some small negative values occur along the global ocean coastline south of 60°N which may or may not be correct.\n",
        "Slope_100\tAverage slope within a 100 meter buffer around the lake polygon, in degrees. This value is derived from the EarthEnv-DEM90 digital elevation model at 90 m pixel resolution. Slopes for each pixel were computed with latitudinal corrections for the distortion in the XY spacing of geographic coordinates by approximating the geodesic distance between cell centers. For 12 lakes located above the northern limit of the EarthEnv-DEM90 digital elevation model (83°N), slopes were computed from the GTOPO30 DEM of USGS at 1 km pixel resolution. -1: slope values were not calculated for the largest lakes (polygon area ≥ 500 km2)\n",
        "Wshd_area\tArea of the watershed associated with the lake, in square kilometers. The watershed area is calculated by deriving and measuring the upstream contribution area to the lake pour point using the HydroSHEDS drainage network map at 15 arc-second resolution. -9999: no data as lake pour point is not on HydroSHEDS landmask\n",
        "Pour_long\tLongitude of the lake pour point, in decimal degrees.\n",
        "Pour_lat\tLatitude of the lake pour point, in decimal degrees.\n",
        "\"\"\"\n",
        "\n",
        "if True:\n",
        "  task = f\"\"\"\n",
        "  Your goal is to compute theoretical vs actual lake outlines and discuss how well they match.\n",
        "Pick at random a lake in an are that you expect to be moderately challenging.\n",
        "For reference, use the Hydrolakes dataset '{hydrolakes_dataset_id}'.\n",
        "Here are the feature properties for the Hydrolakes dataset:\n",
        "\"\"\" + hydrolakes_schema\n",
        "\n",
        "if False:\n",
        "  task = \"\"\"\n",
        "Examine the datasets UCSB-CHG/CHIRPS/DAILY and NOAA/PERSIANN-CDR.\n",
        "Your goal is to understand them and how they differ as deeply as possible.\n",
        "Do not stop until your understanding is complete. Don't try to do everything at once.\n",
        "You can return many short answers that help solve the problem - I will prompt you to continue.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "090IIglOy8VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper classes for IO and code execution"
      ],
      "metadata": {
        "id": "R0jQbFJfzBy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The agent needs three helper classes:\n",
        "# * ColabIOManager knows how to interact with Colab\n",
        "# * Supervisor keeps track of agent state and helps it terminate\n",
        "# * CustomLoggingHandler captures logs from code parsing and execution\n",
        "\n",
        "STARS = '*' * 20 + '\\n'\n",
        "\n",
        "class IOState(enum.StrEnum):\n",
        "  THINKING = 'THINKING'\n",
        "  RUNNING_CODE = 'RUNNING_CODE'\n",
        "  WAITING_FOR_USER_INPUT = 'WAITING_FOR_USER_INPUT'\n",
        "  DONE = 'DONE'\n",
        "\n",
        "\n",
        "class IOManager:\n",
        "  \"\"\"Base class for I/O strategies.\"\"\"\n",
        "\n",
        "  def task_done(self, done_message: str='') -> None:\n",
        "    if done_message.strip():\n",
        "      self.display(f\"Agent said: {done_message.strip()}\\n\")\n",
        "    self.display(\"Task Done!\")\n",
        "\n",
        "  def display(self, text: str) -> None:\n",
        "      raise NotImplementedError\n",
        "\n",
        "  def set_state(self, state: IOState):\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "class Supervisor:\n",
        "  \"\"\"Class responsible for controlling the agent.\"\"\"\n",
        "\n",
        "  # A public property indicating whether the agent is running\n",
        "  running: bool\n",
        "  _io_manager: IOManager\n",
        "\n",
        "  def __init__(self, io_manager):\n",
        "    self.running = False\n",
        "    self._io_manager = io_manager\n",
        "\n",
        "  def syscalls(self):\n",
        "    return [self.task_done, get_dataset_description]\n",
        "\n",
        "  def task_done(self, done_message: str='') -> None:\n",
        "    \"\"\"Signals the agent that the task is done to terminate execution.\"\"\"\n",
        "    self.running = False\n",
        "    self._io_manager.task_done(done_message)\n",
        "\n",
        "def set_cursor_waiting():\n",
        "    js_code = \"\"\"\n",
        "    document.querySelector('body').style.cursor = 'wait';\n",
        "    \"\"\"\n",
        "    display(HTML(f\"<script>{js_code}</script>\"))\n",
        "\n",
        "def set_cursor_default():\n",
        "    js_code = \"\"\"\n",
        "    document.querySelector('body').style.cursor = 'default';\n",
        "    \"\"\"\n",
        "    display(HTML(f\"<script>{js_code}</script>\"))\n",
        "\n",
        "\n",
        "class ColabIOManager(IOManager):\n",
        "  \"\"\"I/O Manager for Google Colab execution.\n",
        "\n",
        "  This class exists to connect logging output from code parsing and execution\n",
        "  to the Colab UI.\n",
        "  \"\"\"\n",
        "\n",
        "  _ui_container: widgets.VBox\n",
        "\n",
        "  def __init__(self):\n",
        "    self._user_input_handler = None\n",
        "    self._output_text = ''\n",
        "\n",
        "    # Create output area with a unique ID\n",
        "    self._output_id = f\"output_{int(time.time())}\"\n",
        "    self._output_area = widgets.Output(\n",
        "        layout=widgets.Layout(\n",
        "            width='50%',\n",
        "            height='600px',\n",
        "            border='1px solid black',\n",
        "            overflow='auto'\n",
        "        )\n",
        "    )\n",
        "    # Add a unique CSS class to output area\n",
        "    self._output_area.add_class(self._output_id)\n",
        "\n",
        "    # Inner Container\n",
        "    hbox = widgets.HBox([\n",
        "        self._output_area,\n",
        "        Map,\n",
        "    ], layout=widgets.Layout(width='100%'))\n",
        "\n",
        "    self._command_input = widgets.Text(\n",
        "        placeholder='Type your message and press Enter...',\n",
        "        description='❓',\n",
        "        value = task,\n",
        "        layout=widgets.Layout(width='95%')\n",
        "    )\n",
        "\n",
        "    # Container for the UI elements\n",
        "    self._ui_container = widgets.VBox([\n",
        "        hbox,\n",
        "        self._command_input,\n",
        "    ], layout=widgets.Layout(width='100%'))\n",
        "\n",
        "    # Add CSS styling\n",
        "    display(HTML(\"\"\"\n",
        "    <style>\n",
        "    .widget-text input[type=\"text\"] {\n",
        "        width: 100% !important;\n",
        "        padding: 8px;\n",
        "        margin: 8px 0;\n",
        "        box-sizing: border-box;\n",
        "    }\n",
        "    .jupyter-widgets-output-area {\n",
        "        overflow-y: auto !important;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\"))\n",
        "\n",
        "    self._command_input.on_submit(self._on_command)\n",
        "\n",
        "  def start(self):\n",
        "    display(self._ui_container)\n",
        "\n",
        "  def _set_emoji(self, emoji):\n",
        "    self._command_input.description = emoji\n",
        "\n",
        "  def set_state(self, state: IOState):\n",
        "    match state:\n",
        "      case IOState.THINKING:\n",
        "        self._set_emoji('🤔')\n",
        "      case IOState.RUNNING_CODE:\n",
        "        self._set_emoji('🌎')\n",
        "      case IOState.WAITING_FOR_USER_INPUT:\n",
        "        self._set_emoji('❓')\n",
        "      case IOState.DONE:\n",
        "        self._set_emoji('✅ ')\n",
        "      case _:\n",
        "        self._set_emoji('🦙')\n",
        "\n",
        "  def _on_command(self, widget):\n",
        "    \"\"\"Accepts user input and passes it to the agent.\"\"\"\n",
        "    set_cursor_waiting()\n",
        "    message = widget.value\n",
        "    if message.strip():\n",
        "      self.display(f\"> {message}\")\n",
        "      widget.value = ''\n",
        "\n",
        "      if self._user_input_handler:\n",
        "        self._user_input_handler(message)\n",
        "    set_cursor_default()\n",
        "\n",
        "  def set_user_input_handler(self, handler):\n",
        "    \"\"\"Sets a handler function to be called when the user submits input.\"\"\"\n",
        "    self._user_input_handler = handler\n",
        "\n",
        "  def display(self, text: str) -> None:\n",
        "    text = text.strip()\n",
        "    if text.endswith('None'):\n",
        "      text = text[:-4]\n",
        "    text = text.strip()\n",
        "    self._output_text += (text + '\\n')\n",
        "    with self._output_area:\n",
        "      display(HTML(f\"<p style='white-space: pre-wrap;'>{text}</p>\"))\n",
        "    self._scroll_to_bottom()\n",
        "\n",
        "  def _scroll_to_bottom(self):\n",
        "    js_code = f\"\"\"\n",
        "        requestAnimationFrame(() => {{\n",
        "            const element = document.querySelector('.{self._output_id}');\n",
        "            if (element) {{\n",
        "                element.scrollTop = element.scrollHeight;\n",
        "            }}\n",
        "        }});\n",
        "    \"\"\"\n",
        "    display(Javascript(js_code))\n",
        "\n",
        "\n",
        "class CustomLoggingHandler(logging.Handler):\n",
        "  \"\"\"Csustom logging handler that sends agent internal logs to the Colab UI.\"\"\"\n",
        "  _io_manager: IOManager\n",
        "\n",
        "  def __init__(self, io_manager):\n",
        "    super().__init__(logging.INFO)\n",
        "    self._io_manager = io_manager\n",
        "\n",
        "  def emit(self, record):\n",
        "    msg = self.format(record)\n",
        "    self._io_manager.display(msg)"
      ],
      "metadata": {
        "id": "MBgMPTNmzEce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "io_manager = ColabIOManager()"
      ],
      "metadata": {
        "id": "OEVFLHDMmBhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab agent"
      ],
      "metadata": {
        "id": "MSLQ7O89zHBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import tokenize\n",
        "\n",
        "# TODO(simonf): move to functionsmith\n",
        "def strip_comments(code):\n",
        "  result = []\n",
        "  tokens = tokenize.tokenize(io.BytesIO(code.encode()).readline)\n",
        "\n",
        "  prev_toktype = tokenize.INDENT\n",
        "  last_lineno = -1\n",
        "  last_col = 0\n",
        "\n",
        "  for tok in tokens:\n",
        "    token_type = tok[0]\n",
        "    token_string = tok[1]\n",
        "    start_line, start_col = tok[2]\n",
        "    end_line, end_col = tok[3]\n",
        "\n",
        "    # The following two conditionals preserve indentation\n",
        "    if start_line > last_lineno:\n",
        "        last_col = 0\n",
        "    if start_col > last_col:\n",
        "        result.append(\" \" * (start_col - last_col))\n",
        "\n",
        "    # Skip comments and docstrings\n",
        "    if token_type == tokenize.COMMENT:\n",
        "      pass\n",
        "    elif token_type == tokenize.STRING:\n",
        "      if prev_toktype != tokenize.INDENT:\n",
        "        # This is likely a docstring; skip it\n",
        "        if prev_toktype != tokenize.NEWLINE:\n",
        "            # This is a string literal; keep it\n",
        "            result.append(token_string)\n",
        "    else:\n",
        "      # This token is not a comment or docstring\n",
        "      result.append(token_string)\n",
        "\n",
        "    prev_toktype = token_type\n",
        "    last_col = end_col\n",
        "    last_lineno = end_line\n",
        "\n",
        "  return ''.join(result)"
      ],
      "metadata": {
        "id": "UKg2XlcMqkjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TURNS = 100\n",
        "\n",
        "class Agent:\n",
        "  \"\"\"Main class for running the agent.\"\"\"\n",
        "  _llm: llm.LLM\n",
        "  _num_turns: int\n",
        "\n",
        "  # The twp dictionaries below will contain functions that the LLM can call.\n",
        "  # The _syscalls dict has system functions - they are defined\n",
        "  # by the agent beforehand. Their output is not intercepted.\n",
        "  # The _functions dict will have functions dynamically created by the LLM.\n",
        "  _syscalls: dict[str, code_parser.Function]\n",
        "  _functions: dict[str, code_parser.Function]\n",
        "\n",
        "  _io_manager: IOManager\n",
        "  _supervisor: Supervisor\n",
        "  _code_parser: code_parser.Parser\n",
        "  _code_executor: executor.Executor\n",
        "\n",
        "  def __init__(self, io_manager: IOManager, llm_interface: llm.LLM):\n",
        "    self._io_manager = io_manager\n",
        "    io_manager.set_user_input_handler(self.handle_user_input)\n",
        "    self._supervisor = Supervisor(io_manager)\n",
        "\n",
        "    self._llm = llm_interface\n",
        "    self._io_manager.display(\n",
        "        f'LLM: {llm_interface.__class__.__name__} {llm_interface._model_name}')\n",
        "    self._syscalls = {}\n",
        "    self._functions = {}\n",
        "\n",
        "    logger = self._create_logger()\n",
        "    self._code_parser = code_parser.Parser(logger)\n",
        "    self._code_executor = executor.Executor(logger)\n",
        "\n",
        "    self._extract_syscalls()\n",
        "\n",
        "  def _create_logger(self):\n",
        "    logger = logging.getLogger('EE Companion')\n",
        "    logger.handlers = []\n",
        "    logger.addHandler(CustomLoggingHandler(self._io_manager))\n",
        "    logger.propagate = False\n",
        "    return logger\n",
        "\n",
        "  def _extract_syscalls(self):\n",
        "    \"\"\"Extracts system calls from the IO manager.\"\"\"\n",
        "    for method in self._supervisor.syscalls():\n",
        "      supervisor_syscalls = self._code_parser.extract_functions(\n",
        "          inspect.getsource(method))\n",
        "      self._syscalls.update(supervisor_syscalls.functions)\n",
        "\n",
        "  def _get_llm_response(self, question: str) -> code_parser.ParsedResponse:\n",
        "    self._io_manager.set_state(IOState.THINKING)\n",
        "    response = self._llm.chat(question)\n",
        "    self._io_manager.display(f\"Agent: {response}\")\n",
        "    return self._code_parser.extract_functions(response)\n",
        "\n",
        "  def _handle_no_code_response(self):\n",
        "    \"\"\"Handles the case where the LLM response has no code.\"\"\"\n",
        "    self._io_manager.set_state(IOState.WAITING_FOR_USER_INPUT)\n",
        "    self._supervisor.running = False\n",
        "\n",
        "  def _execute_code(self, code: str) -> str:\n",
        "    code_sans_comments = strip_comments(code)\n",
        "\n",
        "    for existing in ['task_done', 'get_dataset_description']:\n",
        "      if f'def {existing}(' in code_sans_comments:\n",
        "        error = f\"ERROR: DO NOT define {existing}; it's already defined.\"\n",
        "        self._io_manager.display(error)\n",
        "        return error\n",
        "\n",
        "    if 'ee.Initialize(' in code_sans_comments:\n",
        "      error = \"ERROR: DO NOT call ee.Initialize. It was already called.\"\n",
        "      self._io_manager.display(error)\n",
        "      return error\n",
        "\n",
        "    if 'geemap.Map(' in code_sans_comments:\n",
        "      error = \"ERROR: DO NOT create the geemap object. One is already created.\"\n",
        "      self._io_manager.display(error)\n",
        "      return error\n",
        "\n",
        "    if 'getMapId' in code_sans_comments:\n",
        "      error = \"ERROR: DO NOT use getMapId.\"\n",
        "      self._io_manager.display(error)\n",
        "      return error\n",
        "\n",
        "    sandbox_env = {\n",
        "      'task_done': self._supervisor.task_done,\n",
        "    }\n",
        "    if 'task_done(' not in code_sans_comments:\n",
        "      for layer in Map.layers[2:]:\n",
        "        Map.remove(layer.name)\n",
        "\n",
        "    self._io_manager.set_state(IOState.RUNNING_CODE)\n",
        "    code_globals = {\n",
        "        'ee': ee, 'geemap': geemap, 'Map': Map,\n",
        "        'get_dataset_description': get_dataset_description\n",
        "    }\n",
        "    return self._code_executor.run_code(code, sandbox_env, code_globals)\n",
        "\n",
        "  def handle_user_input(self, user_input):\n",
        "    question = user_input + ' Call task_done() when you think the task is completed.'\n",
        "    self._supervisor.running = True\n",
        "    self._num_turns = 0\n",
        "\n",
        "    # To respond to user input, we run an infinite loop until one of these\n",
        "    # things happens:\n",
        "    # 1. The agent returns a response without any code, which probably means\n",
        "    #    it's asking the user something.\n",
        "    # 2. The agent is no longer running, which probably means it thinks\n",
        "    #    the task is done.\n",
        "    while self._supervisor.running:\n",
        "      self._io_manager.display(STARS)\n",
        "      self._num_turns += 1\n",
        "      if self._num_turns > MAX_TURNS:\n",
        "        self._io_manager.display(f'REACHED {MAX_TURNS} TURNS, TERMINATING')\n",
        "        return\n",
        "\n",
        "      all_tools = copy.deepcopy(self._functions)\n",
        "      all_tools.update(self._syscalls)\n",
        "      function_definitions = '\\n'.join([str(x) for x in all_tools.values()])\n",
        "      question_with_tools = (\n",
        "          f'{question}\\n The following functions are available:\\n'\n",
        "          f'{function_definitions}')\n",
        "\n",
        "      parsed_response = self._get_llm_response(question_with_tools)\n",
        "\n",
        "      if not parsed_response.code and not parsed_response.functions:\n",
        "        if parsed_response.error:\n",
        "          # We couldn't parse the LLM-produced code, so we send the parsing\n",
        "          # error to the LLM.\n",
        "          question = parsed_response.error\n",
        "          continue\n",
        "\n",
        "        # The answer has no functions or top-level code.\n",
        "        # We return control to the user.\n",
        "        self._handle_no_code_response()\n",
        "        return\n",
        "\n",
        "      # If we are here, the response has top-level code, functions, or both.\n",
        "      self._functions.update(parsed_response.functions)\n",
        "\n",
        "      if not parsed_response.code:\n",
        "        # The agent only defined functions, but gave no top-level code.\n",
        "        question = 'go on'\n",
        "        continue\n",
        "\n",
        "      # The code execution output is saved into 'question', as it will be\n",
        "      # sent to the LLM as the next user turn.\n",
        "      question = self._execute_code(parsed_response.code)\n",
        "    # End of while loop\n",
        "\n",
        "    self._io_manager.display(STARS)\n",
        "    self._io_manager.set_state(IOState.DONE)\n"
      ],
      "metadata": {
        "id": "NIugaq2CW6Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ee_preamble = (\"\"\"\n",
        "The client is running in a Python notebook with a geemap Map displayed.\n",
        "The Map object already exists - do not reinitialize it.\n",
        "If the code needs to add layers to the map, use the \"Map.addLayer()\" function\n",
        "Note that every time you return code to be run, preexisting geemap layers are\n",
        "deleted. ee.Authenticate() and ee.Initialize() have already been called.\n",
        "\n",
        "When composing Python code, do not use getMapId. Do not escape quotation marks\n",
        "and do not use line continuations in Python code.\n",
        "Whatever the Python code prints will be returned as the execution result.\n",
        "Each code invocation is separate, so local variables are not transferred\n",
        "between them.\n",
        "\n",
        "Make sure to use selfMask() right before vectorizing to shrink the mask to only\n",
        "the valid area.\n",
        "\n",
        "Be sure to use Python, not Javascript, syntax for keyword parameters in\n",
        "Python code (that is, \"function(arg=value)\"). Use capitalized And for chaining\n",
        "filters, as lowercase \"and\" is a reserved word in Python.\n",
        "\n",
        "Before you choose a dataset, think about what kind of dataset would be most\n",
        "suitable for the query. Also think about what zoom level would be suitable for\n",
        "the query, keeping in mind that for high-resolution image collections higher\n",
        "zoom levels are better to speed up tile loading. Earth Engine datasets often\n",
        "can be very large - read them in small chunks. Do not aggregate properties over\n",
        "the whole dataset.\n",
        "\n",
        "Once you have chosen a dataset, read its description using the provided function\n",
        "to see what spatial and temporal range it covers, what bands it has, as well as\n",
        "to find the recommended visualization parameters. Explain\n",
        "why you chose a specific dataset, zoom level and map location.\n",
        "\n",
        "There is no ee.Date.now() function.\n",
        "\n",
        "If you need to get a few pixel values, use ee.data.getPixels()\n",
        "\n",
        "If you call functions that expect the Map object, pass them the real Map object\n",
        "that is already defined and not a dummy one.\n",
        "\n",
        "Before running a large-scale operation like mosaic() or reduceRegions(), first\n",
        "try retrieving individual pixels\n",
        "and then small data chunks using ee.data.computePixels()\n",
        "with fileFormat=NUMPY_NDARRAY to verify that the source data for the area of\n",
        "interest are present and have expected values. Example:\n",
        "image_grid = {'dimensions': {'width': 5, 'height': 10}}\n",
        "values = ee.data.computePixels({\n",
        "        'expression': ee.Image('LANDSAT/LC08/C02/T1/LC08_044034_20140318'),\n",
        "        'grid': image_grid,\n",
        "        'bandIds': ['B1'],\n",
        "        'fileFormat': 'NUMPY_NDARRAY'})\n",
        "\n",
        "Prefer mosaicing image collections using functions like mosaic() or median(),\n",
        "don't get individual images from collections via\n",
        "'first()'. Choose a tile size and zoom level that will ensure the\n",
        "tile has enough pixels in it to avoid graininess, but not so many\n",
        "that processing becomes very expensive. Do not use wide date ranges\n",
        "with collections that have many images, but remember that Landsat and\n",
        "Sentinel-2 have revisit period of several days. Do not use sample\n",
        "locations - try to come up with actual locations that are relevant to\n",
        "the request.\n",
        "\n",
        "If you are visualizing a layer on the map, you do not need to\n",
        "clip it to the region of interest.\n",
        "\n",
        "If you get the error \"Parameter 'image' is required.\", you are trying to get\n",
        "an image from an empty image collection, likely because the collection filtering\n",
        "is too strict.\n",
        "\n",
        "When using first() to fetch an element from a FeatureCollection, wrap\n",
        "the output in ee.Feature():\n",
        "ee.Feature(ee.FeatureCollection(\"asset_id\").filter()... .first())\n",
        "Do this if you get the error \"Parameter 'feature' is required.\" or if a layer\n",
        "with a single feature is not added to geemap.\n",
        "\n",
        "Use Landsat Collection 2, not Landsat Collection 1 ids. They look like this:\n",
        "LANDSAT/LC08/C02/T1 or LANDSAT/LC08/C02/T1_L2\n",
        "\n",
        "If you are getting\n",
        "repeated errors when filtering by a time range, read the dataset description\n",
        "to confirm that the dataset has data for the selected range.\n",
        "\n",
        "If you need any clarification about Earth Engine functionality or additional\n",
        "information to complete a task, please ask the user before proceeding.\n",
        "If an Earth Engine operation might take a long time to process or return a\n",
        "large amount of data, mention this and suggest ways to optimize or limit\n",
        "the scope if necessary.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "Ia3-ip4Ll0k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start the agent"
      ],
      "metadata": {
        "id": "JQ4IvHAdzJ9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_instruction += ee_preamble\n",
        "#llm_interface = llm.Gemini(system_instruction, api_key=userdata.get('GOOGLE_API_KEY'), model_name='gemini-2.0-flash')\n",
        "#llm_interface = llm.Gemini(system_instruction, api_key=userdata.get('GOOGLE_API_KEY'), model_name='gemini-2.0-flash-thinking-exp-01-21')\n",
        "llm_interface = llm.Gemini(system_instruction, api_key=userdata.get('GOOGLE_API_KEY'), model_name='gemini-2.5-pro-exp-03-25')\n",
        "#llm_interface= llm.Claude(system_instruction, api_key=userdata.get('ANTHROPIC_API_KEY'), model_name='claude-3-7-sonnet-20250219')\n",
        "#llm_interface = llm.ChatGPT(system_instruction, api_key=userdata.get('OPENAI_API_KEY'), model_name='gpt-4o')\n",
        "#llm_interface = llm.DeepSeek(system_instruction, api_key=userdata.get('DEEPSEEK_API_KEY'))\n",
        "\n",
        "agent = Agent(io_manager, llm_interface)\n",
        "io_manager.start()\n",
        "\n",
        "print(\"\"\"\n",
        "Legend:\n",
        "❓ = Waiting for user input\n",
        "🤔 = Thinking\n",
        "🌎 = Running code\n",
        "✅ = The task is done\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "EVLJ1sQwXCG8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}