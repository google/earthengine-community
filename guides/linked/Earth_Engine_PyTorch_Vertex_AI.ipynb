{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSIfBsgi8dNK"
      },
      "source": [
        "#@title Copyright 2023 Google LLC. { display-mode: \"form\" }\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1xZ1CPi3Nw"
      },
      "source": [
        "<table class=\"ee-notebook-buttons\" align=\"left\"><td>\n",
        "<a target=\"_blank\"  href=\"http://colab.research.google.com/github/google/earthengine-community/blob/master/guides/linked/Earth_Engine_PyTorch_Vertex_AI.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
        "</td><td>\n",
        "<a target=\"_blank\"  href=\"https://github.com/google/earthengine-community/blob/master/guides/linked/Earth_Engine_PyTorch_Vertex_AI.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a></td></table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC8adBmw-5m3"
      },
      "source": [
        "# Connecting Earth Engine to a Vertex AI hosted PyTorch model\n",
        "\n",
        "This notebook demonstrates training a per-pixel neural network in PyTorch, hosting the model on Vertex AI, and using it in Earth Engine for interactive prediction using `ee.Model.fromVertexAi` with the `'ND_ARRAYS'` payloadFormat parameter.\n",
        "\n",
        "**Running this demo may incur charges to your Google Cloud Account!**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "xICc7SyIbXav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import ee\n",
        "\n",
        "import google\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "E-nnPe9x8BBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate the notebook.\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "K1VPnt9xhpbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REPLACE WITH YOUR CLOUD PROJECT!\n",
        "PROJECT = 'your-project'\n",
        "\n",
        "# Authenticate to Earth Engine.\n",
        "credentials, _ = google.auth.default()\n",
        "ee.Initialize(credentials, project=PROJECT, opt_url='https://earthengine-highvolume.googleapis.com')"
      ],
      "metadata": {
        "id": "-2eaoMwBegMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the gcloud project for Vertex AI deployment.\n",
        "!gcloud config set project {PROJECT}"
      ],
      "metadata": {
        "id": "O9oagdxYoYw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrXLkJC2QJdP"
      },
      "source": [
        "## Define variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHTOc5YLQZ5B"
      },
      "source": [
        "\"\"\" Training variables\"\"\"\n",
        "\n",
        "# Cloud Storage bucket with training and testing datasets.\n",
        "DATA_BUCKET = 'ee-docs-demos'\n",
        "TRAIN_FILE_PATH = 'gs://' + DATA_BUCKET + '/Pytorch_training_demo.csv'\n",
        "TEST_FILE_PATH = 'gs://' + DATA_BUCKET + '/Pytorch_testing_demo.csv'\n",
        "\n",
        "# Training parameters.\n",
        "BANDS = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "INPUT_TILE_X_DIM = 1\n",
        "INPUT_TILE_Y_DIM = 1\n",
        "BATCH_SIZE = 4\n",
        "OUTPUT_CLASS = 'landcover'\n",
        "\n",
        "\n",
        "\"\"\" Model deployment variables\"\"\"\n",
        "\n",
        "# Output bucket for trained models. REPLACE WITH YOUR WRITABLE BUCKET!\n",
        "OUTPUT_BUCKET = 'gs://your-bucket'\n",
        "\n",
        "# Metadata for model deployment\n",
        "REGION = 'us-central1'\n",
        "MODEL_NAME = 'vertex_pytorch_demo'\n",
        "MODEL_DIR = OUTPUT_BUCKET + '/' + MODEL_NAME\n",
        "CONTAINER_IMAGE = 'us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu.1-12:latest'\n",
        "ENDPOINT_NAME = 'vertex-pytorch-demo-endpoint'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare training data\n",
        "\n",
        "The training data are landcover labels with a single vector of Landsat 8 pixel values (BANDS) as predictors. See [this Code Editor script](https://code.earthengine.google.com/a96ddba52131951f5613c88a0ceb8a96) for an example on how to generate this training data."
      ],
      "metadata": {
        "id": "vWfUHgKOZj8Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sosRFEDdOMA"
      },
      "source": [
        "## Read into tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install additional package\n",
        "!pip install gcsfs"
      ],
      "metadata": {
        "id": "AJXDdOP_gFiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the training data into a Pandas dataframe.\n",
        "df_train = pd.read_csv(TRAIN_FILE_PATH)\n",
        "\n",
        "# Split into features and labels.\n",
        "features = df_train[BANDS].values\n",
        "target = df_train[OUTPUT_CLASS].values\n",
        "\n",
        "# Convert to PyTorch tensors.\n",
        "features = torch.tensor(features, dtype=torch.float32)\n",
        "target = torch.tensor(target, dtype=torch.long)"
      ],
      "metadata": {
        "id": "LNXnDV6CFcmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshape tensors\n",
        "\n",
        " Once we have the data as tensors, we need to reshape the features and target to have the shape that our PyTorch model will expect as input."
      ],
      "metadata": {
        "id": "vMEw2yLjsJ2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_features = torch.reshape(features, (-1, len(BANDS), INPUT_TILE_X_DIM, INPUT_TILE_Y_DIM))\n",
        "print(reshaped_features.shape)\n",
        "\n",
        "reshaped_targets = torch.reshape(target, (-1, INPUT_TILE_X_DIM, INPUT_TILE_Y_DIM))\n",
        "print(reshaped_targets.shape)"
      ],
      "metadata": {
        "id": "ZeSVhHCJsJK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load tensors into a `DataLoader`\n",
        "\n",
        "Finally, we load the tensors into a PyTorch DataLoader, which makes it easier to batch and shuffle the data for training."
      ],
      "metadata": {
        "id": "Eof6eoPqskfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(reshaped_features, reshaped_targets)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "Cg1a3K0MsFaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model setup\n",
        "\n",
        "Now we will define and train a simple landcover classification model with 2 convolutional layers. Note that the model used here is purely for demonstration purposes."
      ],
      "metadata": {
        "id": "bt6lbwTr2ioE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model"
      ],
      "metadata": {
        "id": "kIRwu6EN3Uxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ClassificationModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=len(BANDS), out_channels=15, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=15, out_channels=3, kernel_size=1)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = ClassificationModel()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "djuL9DdBnqd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the training data.\n",
        "num_epochs = 13\n",
        "for epoch in range(num_epochs):\n",
        "  for inputs, targets in train_loader:\n",
        "    # Forward pass\n",
        "    output = model(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  # Print the loss every other epoch\n",
        "  if (epoch) % 2 == 0:\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "sNRaD75jUelA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model"
      ],
      "metadata": {
        "id": "eBKjqoXy22Ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is trained! Now let's test how well our model is able to classify our target landcover classes. When we prepared the training data, we reserved 30% of it for testing. Let's read that testing data from Cloud Storage now and prepare it for our model."
      ],
      "metadata": {
        "id": "QUVeJrIzZa1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(TEST_FILE_PATH)\n",
        "\n",
        "testing_features = torch.tensor(df_test[BANDS].values, dtype=torch.float32)\n",
        "testing_target = torch.tensor(df_test[OUTPUT_CLASS].values, dtype=torch.long)\n",
        "\n",
        "reshaped_testing_features = torch.reshape(testing_features, (-1, len(BANDS), INPUT_TILE_X_DIM, INPUT_TILE_Y_DIM))\n",
        "reshaped_testing_target = torch.reshape(testing_target, (-1, INPUT_TILE_X_DIM, INPUT_TILE_Y_DIM))"
      ],
      "metadata": {
        "id": "0mrWhzNlo1fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can pass the testing features to our model and compare the returned predictions with the ground truth targets to get an accuracy percentage."
      ],
      "metadata": {
        "id": "op7SLZFQZhlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_predictions = model(reshaped_testing_features)\n",
        "\n",
        "testing_loss = criterion(test_predictions, reshaped_testing_target)\n",
        "\n",
        "print(\"Loss is:\", testing_loss)\n",
        "\n",
        "test_predicted_labels = torch.argmax(test_predictions, dim=1)\n",
        "accuracy = (test_predicted_labels == reshaped_testing_target).float().mean()\n",
        "print(\"Accuracy is:\", accuracy)"
      ],
      "metadata": {
        "id": "f8btFdrlpKSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model artifacts\n",
        "\n",
        "Once we're happy with our model architecture and accuracy, we can move on to preparing all of the model artifacts we'll need to deploy it on Vertex AI."
      ],
      "metadata": {
        "id": "eKTfrAfSdVou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model's script module"
      ],
      "metadata": {
        "id": "JkJauSEtgBM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pytorch_model\n",
        "script_module = torch.jit.script(model)\n",
        "script_module.save('pytorch_model/script_module.pt')"
      ],
      "metadata": {
        "id": "icSfDutcKkA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write a custom handler"
      ],
      "metadata": {
        "id": "CNby4yV0f_EW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to specify a handler for our model. We could  use a Torchserve default handler or write a custom one. Here, our model returns per-class probabilities, so we'll write a custom handler to call argmax on the probabilites and return the highest-probability class value to Earth Engine."
      ],
      "metadata": {
        "id": "STWSevy7gJga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pytorch_model/custom_handler.py\n",
        "\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "from ts.torch_handler.base_handler import BaseHandler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ClassifierHandler(BaseHandler):\n",
        "\n",
        "  def postprocess(self, data):\n",
        "    # Data comes in as a pytorch tensor of probabilities, so use argmax to\n",
        "    # select the class with the highest probability.\n",
        "    predictions = torch.argmax(data, dim=1).float()\n",
        "\n",
        "    # Return the data as a list.\n",
        "    return predictions.tolist()\n",
        "\n",
        "  def handle(self, data, context):\n",
        "    self.context = context\n",
        "\n",
        "    input_tensor = self.preprocess(data)\n",
        "    pred_out = self.inference(input_tensor)\n",
        "    return self.postprocess(pred_out)"
      ],
      "metadata": {
        "id": "KpK6rHs5E8EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save a model archive"
      ],
      "metadata": {
        "id": "eVXPnJ6IBwOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-model-archiver"
      ],
      "metadata": {
        "id": "tAXOY3ZSgmdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!torch-model-archiver -f \\\n",
        "  --model-name model \\\n",
        "  --version 1.0 \\\n",
        "  --serialized-file 'pytorch_model/script_module.pt' \\\n",
        "  --handler 'pytorch_model/custom_handler.py' \\\n",
        "  --export-path pytorch_model/"
      ],
      "metadata": {
        "id": "OSujqQj3R7te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy files to GCS"
      ],
      "metadata": {
        "id": "RtYE43kTYQTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the bucket if it doesn't exist\n",
        "!gcloud storage buckets create {OUTPUT_BUCKET}"
      ],
      "metadata": {
        "id": "t30DZcgwLLkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp -r pytorch_model {MODEL_DIR}"
      ],
      "metadata": {
        "id": "7-nd0xA8YQTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy to Vertex AI"
      ],
      "metadata": {
        "id": "msy_hCJHd89F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the model\n",
        "Upload the saved model to Vertex's model registry, providing the model's Cloud Storage location and desired container image. See [Vertex Docs](https://cloud.google.com/sdk/gcloud/reference/ai/models/upload) for more info."
      ],
      "metadata": {
        "id": "SWSlwmYwVtGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai models upload \\\n",
        "  --artifact-uri={MODEL_DIR} \\\n",
        "  --project={PROJECT} \\\n",
        "  --region={REGION} \\\n",
        "  --container-image-uri={CONTAINER_IMAGE} \\\n",
        "  --description={MODEL_NAME} \\\n",
        "  --display-name={MODEL_NAME} \\\n",
        "  --model-id={MODEL_NAME}"
      ],
      "metadata": {
        "id": "ypOvtOV2GRAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an endpoint\n",
        "\n",
        "Create an endpoint from which to serve the model. See [Vertex Docs](https://cloud.google.com/sdk/gcloud/reference/ai/endpoints/create) for more info."
      ],
      "metadata": {
        "id": "UX9KbR5ufzuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai endpoints create \\\n",
        "  --display-name={ENDPOINT_NAME} \\\n",
        "  --endpoint-id={ENDPOINT_NAME} \\\n",
        "  --region={REGION} \\\n",
        "  --project={PROJECT}"
      ],
      "metadata": {
        "id": "_UAEo1sziinc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy the model to the endpoint\n",
        "\n",
        "First, look up the endpoint ID, then deploy the model. See [Vertex Docs](https://cloud.google.com/sdk/gcloud/reference/ai/endpoints/deploy-model) for more info."
      ],
      "metadata": {
        "id": "e7uzlQkOf5dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai endpoints deploy-model {ENDPOINT_NAME} \\\n",
        "  --project={PROJECT} \\\n",
        "  --region={REGION} \\\n",
        "  --model={MODEL_NAME} \\\n",
        "  --display-name={MODEL_NAME}"
      ],
      "metadata": {
        "id": "oQT0ECBh2Bjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aTGza-rWIjp"
      },
      "source": [
        "# Connect to the hosted model from Earth Engine\n",
        "\n",
        "1. Generate the input imagery.  This should be done in exactly the same way as the training data were generated.  See [this example notebook](http://colab.research.google.com/github/google/earthengine-api/blob/master/python/examples/ipynb/TF_demo1_keras.ipynb) for details.\n",
        "2. Connect to the hosted model.\n",
        "3. Use the model to make predictions.\n",
        "4. Display the results.\n",
        "\n",
        "Note that it may take the model a couple minutes to spin up before it is ready to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geemap\n",
        "\n",
        "\n",
        "# The image input data is a 2018 cloud-masked median composite.\n",
        "landsatCollection = ee.ImageCollection('LANDSAT/LC08/C02/T1').filterDate('2018-01-01', '2018-12-31')\n",
        "\n",
        "composite = ee.Algorithms.Landsat.simpleComposite(\n",
        "  collection=landsatCollection,\n",
        "  asFloat=True\n",
        ");\n",
        "\n",
        "# Use geemap to visualize the imagery.\n",
        "Map = geemap.Map(center=(37.8, -122.5), zoom=12)\n",
        "\n",
        "Map.addLayer(\n",
        "    composite,\n",
        "    {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3},\n",
        "    'median composite',\n",
        "    True)\n",
        "\n",
        "endpoint_path = (\n",
        "    'projects/' + PROJECT + '/locations/' + REGION + '/endpoints/' + str(ENDPOINT_NAME))\n",
        "\n",
        "# Connect to the hosted model.\n",
        "vertex_model = ee.Model.fromVertexAi(\n",
        "  endpoint=endpoint_path,\n",
        "  inputTileSize=[50, 50],\n",
        "  proj=ee.Projection('EPSG:4326').atScale(30),\n",
        "  fixInputProj=True,\n",
        "  outputBands={'output': {\n",
        "      'type': ee.PixelType.float(),\n",
        "      'dimensions': 0\n",
        "    }},\n",
        "  payloadFormat='ND_ARRAYS'\n",
        "  )\n",
        "\n",
        "predictions = vertex_model.predictImage(composite.select(BANDS))\n",
        "\n",
        "Map.addLayer(\n",
        "    predictions,\n",
        "    {'min': 0, 'max': 2, 'palette': ['red', 'green', 'blue']},\n",
        "    'predictions',\n",
        "    True)\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "jjsbdhUGApFU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
