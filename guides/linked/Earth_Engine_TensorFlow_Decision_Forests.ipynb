{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSIfBsgi8dNK"
      },
      "source": [
        "#@title Copyright 2023 Google LLC. { display-mode: \"form\" }\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1xZ1CPi3Nw"
      },
      "source": [
        "\u003ctable class=\"ee-notebook-buttons\" align=\"left\"\u003e\u003ctd\u003e\n",
        "\u003ca target=\"_blank\"  href=\"http://colab.research.google.com/github/google/earthengine-community/blob/master/guides/linked/Earth_Engine_TensorFlow_Decision_Forests.ipynb\"\u003e\n",
        "    \u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003e Run in Google Colab\u003c/a\u003e\n",
        "\u003c/td\u003e\u003ctd\u003e\n",
        "\u003ca target=\"_blank\"  href=\"https://github.com/google/earthengine-community/blob/master/guides/linked/Earth_Engine_TensorFlow_Decision_Forests.ipynb\"\u003e\u003cimg width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003e View source on GitHub\u003c/a\u003e\u003c/td\u003e\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a TensorFlow Decision Forest model in Earth Engine\n",
        "\n",
        "[TensorFlow Decision Forests (TF-DF)](https://www.tensorflow.org/decision_forests) is an implementation of popular tree-based machine learning models in TensorFlow.  These models can be trained, saved and hosted on Vertex AI, as with TensorFlow neural networks.  This notebook demonstrates how to install TF-DF, train a random forest, host the model on Vertex AI and get interactive predictions in Earth Engine.  The demonstration model produces a map of land cover from Landsat image data and pre-generated training data.\n",
        "\n",
        "To get started, import the necessary libraries and authenticate.\n",
        "\n",
        "#### **Warning!** This demo consumes billable resources of Google Cloud, including Earth Engine, Vertex AI and Cloud Storage."
      ],
      "metadata": {
        "id": "IbLZzFNVY0d3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCjLEdaWz-fo"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that a specific version of TF-DF needs to be installed.  This is because Vertex AI only supports [specific versions of TensorFlow in pre-built containers](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers).  Although it's possible to build a custom container image with a more recent version, here we'll just use TF-DF version 1.4 so that we don't have to build a custom container image.  See [the TF-DF compatibility table](https://www.tensorflow.org/decision_forests/known_issues#compatibility_table) for more info."
      ],
      "metadata": {
        "id": "zQA-EQfRcb2D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oya_yZSENPqM"
      },
      "outputs": [],
      "source": [
        "!pip3 install -q tensorflow_decision_forests==1.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--e-j3AIM9xl"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import folium\n",
        "from google.colab import auth\n",
        "import google\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure this matches the TF-DF version installed above.  (Should be 2.12.0 to match TF-DF 1.14.0)."
      ],
      "metadata": {
        "id": "wirKBLCBoeOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "O77iM6BWoYva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUgaUUAXNHmU"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "credentials, project = google.auth.default()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# REPLACE WITH YOUR CLOUD PROJECT!\n",
        "PROJECT = 'your-project'\n",
        "# A Cloud Storage bucket into which you can write saved model artifacts.\n",
        "OUTPUT_BUCKET = 'your-bucket'"
      ],
      "metadata": {
        "id": "RQkql50sfId1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqQ4lkyPNKuY"
      },
      "outputs": [],
      "source": [
        "ee.Initialize(credentials, project=PROJECT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfTCaWEQQoBq"
      },
      "outputs": [],
      "source": [
        "# Name of the model output folder in Cloud Storage.\n",
        "MODEL_DIR = 'gs://' + OUTPUT_BUCKET + '/tfdf_demo'\n",
        "\n",
        "# Suitable names for the model and endpoint.\n",
        "MODEL_NAME = 'tfdf-demo-14'\n",
        "ENDPOINT_NAME = 'tfdf-endpoint-14'\n",
        "\n",
        "# A suitable container image for the host machine.\n",
        "CONTAINER_IMAGE = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-12:latest'\n",
        "\n",
        "# Cloud Storage bucket with training and testing datasets.\n",
        "DATA_BUCKET = 'ee-docs-demos'\n",
        "\n",
        "# This is a good region for hosting AI models.\n",
        "REGION = 'us-central1'\n",
        "\n",
        "# Training and testing dataset file names in the Cloud Storage bucket.\n",
        "TRAIN_FILE_PREFIX = 'Training_demo'\n",
        "TEST_FILE_PREFIX = 'Testing_demo'\n",
        "file_extension = '.tfrecord.gz'\n",
        "TRAIN_FILE_PATH = 'gs://' + DATA_BUCKET + '/' + TRAIN_FILE_PREFIX + file_extension\n",
        "TEST_FILE_PATH = 'gs://' + DATA_BUCKET + '/' + TEST_FILE_PREFIX + file_extension\n",
        "\n",
        "# The labels, consecutive integer indices starting from zero, are stored in\n",
        "# this property, set on each point.\n",
        "LABEL = 'landcover'\n",
        "# Number of label values, i.e. number of classes in the classification.\n",
        "N_CLASSES = 3\n",
        "CLASS_NAMES = ['bare', 'veg', 'water']\n",
        "\n",
        "# Use Landsat 8 surface reflectance data for predictors.\n",
        "L8SR = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
        "# Use these bands for prediction.\n",
        "BANDS = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
        "\n",
        "# These names are used to specify properties in the export of\n",
        "# training/testing data and to define the mapping between names and data\n",
        "# when reading into TensorFlow datasets.\n",
        "FEATURE_NAMES = list(BANDS)\n",
        "FEATURE_NAMES.append(LABEL)\n",
        "\n",
        "# List of fixed-length features, all of which are float32.\n",
        "FEATURES_DICT = {\n",
        "    feature_name: tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
        "    for feature_name in FEATURE_NAMES\n",
        "}\n",
        "\n",
        "ATTRIBUTION = 'Map Data \u0026copy; \u003ca href=\"https://earthengine.google.com/\"\u003eGoogle Earth Engine\u003c/a\u003e'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JksMlzaf0ZYG"
      },
      "source": [
        "## Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SfrAZlcQ1Eg"
      },
      "outputs": [],
      "source": [
        "print('Found training file.' if tf.io.gfile.exists(TRAIN_FILE_PATH)\n",
        "    else 'No training file found.')\n",
        "print('Found testing file.' if tf.io.gfile.exists(TEST_FILE_PATH)\n",
        "    else 'No testing file found.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQYxzxQmQ2bL"
      },
      "outputs": [],
      "source": [
        "# Create a dataset from the TFRecord file in Cloud Storage.\n",
        "train_dataset = tf.data.TFRecordDataset([TRAIN_FILE_PATH, TEST_FILE_PATH],\n",
        "                                        compression_type='GZIP')\n",
        "\n",
        "# Print the first record to check.\n",
        "iter(train_dataset).next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA61KrlnQ9Jt"
      },
      "outputs": [],
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "\n",
        "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the predictors dictionary and the LABEL, cast to an `int32`.\n",
        "  \"\"\"\n",
        "  parsed_features = tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
        "  labels = parsed_features.pop(LABEL)\n",
        "  return parsed_features, tf.cast(labels, tf.int32)\n",
        "\n",
        "# Map the function over the dataset.\n",
        "parsed_dataset = train_dataset.map(parse_tfrecord, num_parallel_calls=4)\n",
        "\n",
        "# Print the first parsed record to check.\n",
        "iter(parsed_dataset).next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZqg8f7E0epB"
      },
      "source": [
        "## Fit a TensorFlow Decision Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzU1G8BQe4WW"
      },
      "outputs": [],
      "source": [
        "rf_model = tfdf.keras.RandomForestModel(verbose=2)\n",
        "\n",
        "# Train the model.  You can ignore AutoGraph warnings.\n",
        "rf_model.fit(x=parsed_dataset.batch(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V79Gih1l32H"
      },
      "outputs": [],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(rf_model, tree_idx=0, max_depth=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model.summary()"
      ],
      "metadata": {
        "id": "xr0eRZLYLxqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncwsNhjL0pCb"
      },
      "source": [
        "## Reshape inputs/outputs\n",
        "\n",
        "Earth Engine sends and receives data as dictionaries keyed by band, where each band stores a patch.  TF-DF (as a non-spatial model) doesn't know about patches, and instead just receives flattened arrays.  Add some reshaping layers to flatten the inputs and reshape the model outputs into a patch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftM_qQcn5r9i"
      },
      "outputs": [],
      "source": [
        "# Create a custom keras layer to do the reshaping of the input data.\n",
        "class ReshapeInputEE(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "  def call(self, tensor_dict):\n",
        "    return_dict={}\n",
        "    for (k,v) in tensor_dict.items():\n",
        "      return_dict[k] = tf.reshape(v, [-1, 1]) # Flatten\n",
        "    return return_dict\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    return config\n",
        "\n",
        "\n",
        "# This layer reshapes the model predictions to what EE requires.\n",
        "class ReshapeOutputEE(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    input_dict, model_predictions = inputs[0], inputs[1]\n",
        "    # This layer needs to know the shape of the original input data.\n",
        "    shape = tf.shape(list(input_dict.values())[0])\n",
        "    # It should be [batch, height, width, channels]:\n",
        "    return tf.reshape(model_predictions, [-1, shape[1], shape[2], N_CLASSES])\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    return config\n",
        "\n",
        "\n",
        "input_reshaper = ReshapeInputEE(name=\"input_reshaper\")\n",
        "output_reshaper = ReshapeOutputEE(name=\"output_reshaper\")\n",
        "\n",
        "# Create the new inputs: a dictionary keyed by band name where each key\n",
        "# stores a [H, W, 1] patch of inputs for the band.\n",
        "inputs = {b: tf.keras.Input(shape=(None, None, 1), name=b) for b in BANDS}\n",
        "\n",
        "# Create the model.\n",
        "wrapped_model = input_reshaper(inputs)\n",
        "wrapped_model = rf_model(wrapped_model)\n",
        "wrapped_model = output_reshaper([inputs, wrapped_model])\n",
        "wrapped_model = tf.keras.Model(inputs, wrapped_model, name=\"RF_with_reshaping\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6p_54ym0xCz"
      },
      "source": [
        "## De/serialization\n",
        "\n",
        "De/serialization prepares the model for hosting on Google Cloud.  Specifically, you need to provide image data to the Vertex AI API by sending the image data as base64-encoded text ([reference](https://cloud.google.com/vertex-ai/docs/general/base64)).  Wrap the trained model in de/serialization layers to handle the conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRNqZejLknJa"
      },
      "outputs": [],
      "source": [
        "class DeSerializeInput(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "  def call(self, inputs_dict):\n",
        "    return {\n",
        "      k: tf.map_fn(lambda x: tf.io.parse_tensor(x, tf.float32),\n",
        "                   tf.io.decode_base64(v),\n",
        "                   fn_output_signature=tf.float32)\n",
        "        for (k, v) in inputs_dict.items()\n",
        "    }\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    return config\n",
        "\n",
        "\n",
        "class ReSerializeOutput(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "  def call(self, output_tensor):\n",
        "    return tf.map_fn(lambda x: tf.io.encode_base64(tf.io.serialize_tensor(x)),\n",
        "                    output_tensor,\n",
        "                    fn_output_signature=tf.string)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    return config\n",
        "\n",
        "input_deserializer = DeSerializeInput()\n",
        "output_deserializer = ReSerializeOutput()\n",
        "\n",
        "serialized_inputs = {\n",
        "    b: tf.keras.Input(shape=[], dtype='string', name=b) for b in BANDS\n",
        "}\n",
        "\n",
        "updated_model_input = input_deserializer(serialized_inputs)\n",
        "updated_model = wrapped_model(updated_model_input)\n",
        "updated_model = output_deserializer(updated_model)\n",
        "updated_model= tf.keras.Model(serialized_inputs, updated_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjIMDFTz7VYT"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(updated_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alBd3ioS04g3"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nGKQXR88Ccp"
      },
      "outputs": [],
      "source": [
        "# You may ignore compiler and absl warnings.\n",
        "updated_model.save(MODEL_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy the model to Vertex AI"
      ],
      "metadata": {
        "id": "S_Tw8ZBoo0hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai models upload \\\n",
        "  --artifact-uri={MODEL_DIR} \\\n",
        "  --project={PROJECT} \\\n",
        "  --region={REGION} \\\n",
        "  --container-image-uri={CONTAINER_IMAGE} \\\n",
        "  --description={MODEL_NAME} \\\n",
        "  --display-name={MODEL_NAME} \\\n",
        "  --model-id={MODEL_NAME}"
      ],
      "metadata": {
        "id": "H13B9H3NxgXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai endpoints create \\\n",
        "  --display-name={ENDPOINT_NAME} \\\n",
        "  --region={REGION} \\\n",
        "  --project={PROJECT}"
      ],
      "metadata": {
        "id": "BR46f7ZOLJR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENDPOINT_ID = !gcloud ai endpoints list \\\n",
        "  --project={PROJECT} \\\n",
        "  --region={REGION} \\\n",
        "  --filter=displayName:{ENDPOINT_NAME} \\\n",
        "  --format=\"value(ENDPOINT_ID.scope())\"\n",
        "ENDPOINT_ID = ENDPOINT_ID[-1]\n",
        "print(ENDPOINT_ID)"
      ],
      "metadata": {
        "id": "jLLnM0kQLJSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai endpoints deploy-model {ENDPOINT_ID} \\\n",
        "  --project={PROJECT} \\\n",
        "  --region={REGION} \\\n",
        "  --model={MODEL_NAME} \\\n",
        "  --machine-type=n1-standard-4 \\\n",
        "  --display-name={MODEL_NAME}"
      ],
      "metadata": {
        "id": "685rHrdHKw0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aTGza-rWIjp"
      },
      "source": [
        "## Connect to the hosted model from Earth Engine\n",
        "\n",
        "1. Generate the input imagery.  This should be done in exactly the same way as the training data were generated.  See [this example notebook](http://colab.research.google.com/github/google/earthengine-api/blob/master/python/examples/ipynb/TF_demo1_keras.ipynb) for details.\n",
        "2. Connect to the hosted model.\n",
        "3. Use the model to make predictions.\n",
        "4. Display the results.\n",
        "\n",
        "Note that it may take the model a couple minutes to spin up before it is ready to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2OsyrJ7HAhE"
      },
      "source": [
        "def mask_L8_sr(image):\n",
        "  \"\"\"Cloud masking function for Landsat 8, collection 2.\"\"\"\n",
        "  qa_mask = image.select('QA_PIXEL').bitwiseAnd(31).eq(0)\n",
        "  saturation_mask = image.select('QA_RADSAT').eq(0)\n",
        "\n",
        "  optical_bands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
        "  thermal_bands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
        "\n",
        "  return (image.addBands(optical_bands, None, True)\n",
        "                .addBands(thermal_bands, None, True)\n",
        "                .updateMask(qa_mask)\n",
        "                .updateMask(saturation_mask).select('SR_B*.'))\n",
        "\n",
        "# The image input data is a 2018 cloud-masked median composite.\n",
        "image = L8SR.filterDate(\n",
        "    '2018-01-01', '2018-12-31').map(mask_L8_sr).select(BANDS).median().float()\n",
        "\n",
        "# Get a URL to serve image tiles.\n",
        "mapid = image.getMapId({'bands': ['SR_B4', 'SR_B3', 'SR_B2'], 'min': 0, 'max': 0.3})\n",
        "\n",
        "# Use folium to visualize the imagery.\n",
        "map = folium.Map(location=[37.6, -122.3], zoom_start=11)\n",
        "\n",
        "# Inputs.\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr=ATTRIBUTION,\n",
        "    overlay=True,\n",
        "    name='median composite',\n",
        "  ).add_to(map)\n",
        "\n",
        "endpoint_path = (\n",
        "    'projects/' + PROJECT + '/locations/' + REGION + '/endpoints/' + str(ENDPOINT_ID))\n",
        "\n",
        "# Connect to the hosted model.\n",
        "vertex_model = ee.Model.fromVertexAi(\n",
        "  endpoint=endpoint_path,\n",
        "  inputTileSize=[8, 8],\n",
        "  proj=ee.Projection('EPSG:4326').atScale(30),\n",
        "  fixInputProj=True,\n",
        "  outputBands={'output': {\n",
        "      'type': ee.PixelType.float(),\n",
        "      'dimensions': 1\n",
        "    }\n",
        "  })\n",
        "\n",
        "predictions = vertex_model.predictImage(image.select(BANDS).float())\n",
        "probabilities = predictions.arrayFlatten([CLASS_NAMES])\n",
        "probability_vis = {\n",
        "    'bands': CLASS_NAMES, 'min': 0.2, 'max': 0.5, 'format': 'png'\n",
        "}\n",
        "probability_mapid = probabilities.getMapId(probability_vis)\n",
        "folium.TileLayer(\n",
        "    tiles=probability_mapid['tile_fetcher'].url_format,\n",
        "    attr=ATTRIBUTION,\n",
        "    overlay=True,\n",
        "    name='predictions',\n",
        "  ).add_to(map)\n",
        "\n",
        "map.add_child(folium.LayerControl())\n",
        "display(map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Warning!** This demo consumes billable resources of Google Cloud, including Earth Engine, Vertex AI and Cloud Storage.  Be sure to shut down any prediction nodes to avoid ongoing charges."
      ],
      "metadata": {
        "id": "67KfBl7z2OSX"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
